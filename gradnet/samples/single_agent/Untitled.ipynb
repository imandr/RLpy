{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45d82738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from gradnet import Model, Input\n",
    "from gradnet.layers import Dense\n",
    "from gradnet.losses import get_loss, Loss\n",
    "from gradnet.optimizers import get_optimizer\n",
    "from gradnet.metrics import get_metric\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59db358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a84cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntropyLoss(Loss):\n",
    "    \n",
    "    def __init__(self, *inputs, q=0.01, **args):\n",
    "        import math\n",
    "        Loss.__init__(self, *inputs, **args)\n",
    "        assert len(self.Inputs) == 1\n",
    "        N = self.Inputs[0].Shape[-1]\n",
    "        p = 1.0 - (N-1)*q\n",
    "        assert p > q, f\"The target q value for the EntropyLoss ({q}) is too high for the number of dimensions ({N})\"\n",
    "        self.K = 1.0/(p*math.log(q/p))\n",
    "        self.LogN = math.log(N)\n",
    "\n",
    "    def compute(self, data):\n",
    "        probs = self.Inputs[0].Y\n",
    "        #print(\"Entropy loss: probs:\", probs)\n",
    "        p = np.clip(probs, 1e-5, None)\n",
    "        values = -np.sum(p*np.log(p), axis=-1)\n",
    "        grads = np.log(p)+1.0\n",
    "        n = probs.shape[-1]\n",
    "        self.Grads = [grads*self.K]\n",
    "        self.Values = values/self.LogN\n",
    "        return self.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ee43257",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _EntropyLoss(Loss):\n",
    "    \n",
    "    def __init__(self, *inputs, q=0.01, **args):\n",
    "        import math\n",
    "        Loss.__init__(self, *inputs, **args)\n",
    "        self.Q = q\n",
    "\n",
    "    def compute(self, data):\n",
    "        probs = self.Inputs[0].Y\n",
    "        mask = probs < self.Q\n",
    "        d = (probs - self.Q)*mask\n",
    "        self.Values = np.sum(d**2, axis=-1)\n",
    "        self.Grads = [2*d]\n",
    "        return self.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "805f4d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(nin, nout, entropy_weight):\n",
    "    inp = Input((nin,))\n",
    "    hidden = Dense(100, activation=\"relu\")(inp)\n",
    "    probs = Dense(nout, activation=\"softmax\")(hidden)\n",
    "    model = Model(inp, probs)\n",
    "    entropy = EntropyLoss(probs, q=0.1)\n",
    "    cce = get_loss(\"cce\")(probs)\n",
    "    model.add_loss(entropy, entropy_weight, name=\"entropy\")\n",
    "    model.add_loss(cce, name=\"cce\")\n",
    "    model.compile(get_optimizer(\"adagrad\", learning_rate=0.01), metrics=[get_metric(\"accuracy\")])\n",
    "    \n",
    "    model[\"cce\"] = cce\n",
    "    model[\"entropy\"] = entropy\n",
    "    \n",
    "    return model\n",
    "\n",
    "accuracy = get_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1bff138",
   "metadata": {},
   "outputs": [],
   "source": [
    "nin = 5\n",
    "nout = 2\n",
    "w = 1.0\n",
    "mb = 1\n",
    "y_ = np.zeros((mb, nout))\n",
    "y_[:,0] = 0.9\n",
    "y_[:,1] = 0.1\n",
    "model=create_model(nin, nout, w)\n",
    "record = []\n",
    "ma = np.array([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "205a7730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss grads: cce: [[-1.9029 -0.1897]]    entropy: [array([[-0.1271, -0.1818]])]\n",
      "Loss grads: cce: [[-1.0647 -0.6464]]    entropy: [array([[-0.4207,  0.4381]])]\n",
      "Loss grads: cce: [[-0.9668 -1.4468]]    entropy: [array([[-0.4695,  0.8455]])]\n",
      "Loss grads: cce: [[-0.9789 -1.2414]]    entropy: [array([[-0.4632,  0.768 ]])]\n",
      "Loss grads: cce: [[-0.9362 -2.5862]]    entropy: [array([[-0.4857,  1.1392]])]\n",
      "Loss grads: cce: [[-0.9235 -3.9324]]    entropy: [array([[-0.4927,  1.3511]])]\n",
      "Loss grads: cce: [[-0.9619 -1.5533]]    entropy: [array([[-0.472 ,  0.8814]])]\n",
      "Loss grads: cce: [[-0.9324 -2.8741]]    entropy: [array([[-0.4878,  1.1926]])]\n",
      "Loss grads: cce: [[-0.9311 -2.9976]]    entropy: [array([[-0.4885,  1.2138]])]\n",
      "Loss grads: cce: [[-0.9436 -2.1636]]    entropy: [array([[-0.4818,  1.049 ]])]\n",
      "Loss grads: cce: [[-0.9332 -2.8149]]    entropy: [array([[-0.4874,  1.1821]])]\n",
      "Loss grads: cce: [[-0.964  -1.5068]]    entropy: [array([[-0.471,  0.866]])]\n",
      "Loss grads: cce: [[-0.9355 -2.636 ]]    entropy: [array([[-0.4861,  1.1488]])]\n",
      "Loss grads: cce: [[-0.9361 -2.5963]]    entropy: [array([[-0.4858,  1.1412]])]\n",
      "Loss grads: cce: [[-0.9233 -3.967 ]]    entropy: [array([[-0.4928,  1.3555]])]\n",
      "Loss grads: cce: [[-0.9634 -1.5204]]    entropy: [array([[-0.4713,  0.8706]])]\n",
      "Loss grads: cce: [[-0.9701 -1.3838]]    entropy: [array([[-0.4678,  0.823 ]])]\n",
      "Loss grads: cce: [[-0.952  -1.8311]]    entropy: [array([[-0.4773,  0.9646]])]\n",
      "Loss grads: cce: [[-0.9309 -3.0111]]    entropy: [array([[-0.4886,  1.2161]])]\n",
      "Loss grads: cce: [[-0.9381 -2.4635]]    entropy: [array([[-0.4847,  1.1146]])]\n",
      "Loss grads: cce: [[-0.9216 -4.2645]]    entropy: [array([[-0.4937,  1.3921]])]\n",
      "Loss grads: cce: [[-0.9378 -2.478 ]]    entropy: [array([[-0.4849,  1.1176]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5136]]    entropy: [array([[-0.4852,  1.1248]])]\n",
      "Loss grads: cce: [[-0.9649 -1.4876]]    entropy: [array([[-0.4705,  0.8596]])]\n",
      "Loss grads: cce: [[-0.9584 -1.6401]]    entropy: [array([[-0.4739,  0.9089]])]\n",
      "Loss grads: cce: [[-0.9247 -3.7378]]    entropy: [array([[-0.492 ,  1.3255]])]\n",
      "Loss grads: cce: [[-0.9274 -3.3824]]    entropy: [array([[-0.4905,  1.2749]])]\n",
      "Loss grads: cce: [[-0.9239 -3.8592]]    entropy: [array([[-0.4924,  1.3416]])]\n",
      "Loss grads: cce: [[-0.9556 -1.7198]]    entropy: [array([[-0.4754,  0.9329]])]\n",
      "Loss grads: cce: [[-0.9357 -2.6211]]    entropy: [array([[-0.486,  1.146]])]\n",
      "Loss grads: cce: [[-0.9511 -1.8627]]    entropy: [array([[-0.4778,  0.9733]])]\n",
      "Loss grads: cce: [[-0.9242 -3.8239]]    entropy: [array([[-0.4923,  1.337 ]])]\n",
      "Loss grads: cce: [[-0.9445 -2.1224]]    entropy: [array([[-0.4813,  1.0392]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5419]]    entropy: [array([[-0.4854,  1.1305]])]\n",
      "Loss grads: cce: [[-0.975  -1.2995]]    entropy: [array([[-0.4652,  0.7912]])]\n",
      "Loss grads: cce: [[-0.9424 -2.2242]]    entropy: [array([[-0.4824,  1.063 ]])]\n",
      "Loss grads: cce: [[-0.9235 -3.9277]]    entropy: [array([[-0.4926,  1.3505]])]\n",
      "Loss grads: cce: [[-0.9484 -1.9579]]    entropy: [array([[-0.4792,  0.9985]])]\n",
      "Loss grads: cce: [[-0.9325 -2.8681]]    entropy: [array([[-0.4877,  1.1915]])]\n",
      "Loss grads: cce: [[-0.9483 -1.9616]]    entropy: [array([[-0.4792,  0.9994]])]\n",
      "Loss grads: cce: [[-0.9492 -1.9276]]    entropy: [array([[-0.4787,  0.9906]])]\n",
      "Loss grads: cce: [[-0.9468 -2.0223]]    entropy: [array([[-0.48  ,  1.0148]])]\n",
      "Loss grads: cce: [[-0.9274 -3.3877]]    entropy: [array([[-0.4905,  1.2757]])]\n",
      "Loss grads: cce: [[-0.9133 -6.8908]]    entropy: [array([[-0.4983,  1.6348]])]\n",
      "Loss grads: cce: [[-0.9597 -1.6066]]    entropy: [array([[-0.4732,  0.8985]])]\n",
      "Loss grads: cce: [[-0.9706 -1.3744]]    entropy: [array([[-0.4675,  0.8195]])]\n",
      "Loss grads: cce: [[-0.9794 -1.2342]]    entropy: [array([[-0.463 ,  0.7651]])]\n",
      "Loss grads: cce: [[-0.9427 -2.2066]]    entropy: [array([[-0.4822,  1.0589]])]\n",
      "Loss grads: cce: [[-0.969  -1.4052]]    entropy: [array([[-0.4684,  0.8307]])]\n",
      "Loss grads: cce: [[-0.9255 -3.6295]]    entropy: [array([[-0.4916,  1.3106]])]\n",
      "Loss grads: cce: [[-0.9887 -1.1141]]    entropy: [array([[-0.4581,  0.7134]])]\n",
      "Loss grads: cce: [[-0.9508 -1.8717]]    entropy: [array([[-0.4779,  0.9757]])]\n",
      "Loss grads: cce: [[-0.9552 -1.7316]]    entropy: [array([[-0.4756,  0.9363]])]\n",
      "Loss grads: cce: [[-0.9366 -2.56  ]]    entropy: [array([[-0.4855,  1.1341]])]\n",
      "Loss grads: cce: [[-1.0154 -0.8796]]    entropy: [array([[-0.4447,  0.5938]])]\n",
      "Loss grads: cce: [[-0.93   -3.1011]]    entropy: [array([[-0.4891,  1.231 ]])]\n",
      "Loss grads: cce: [[-0.9445 -2.1229]]    entropy: [array([[-0.4813,  1.0394]])]\n",
      "Loss grads: cce: [[-0.9563 -1.6982]]    entropy: [array([[-0.475 ,  0.9265]])]\n",
      "Loss grads: cce: [[-0.9189 -4.8618]]    entropy: [array([[-0.4952,  1.4584]])]\n",
      "Loss grads: cce: [[-0.929  -3.2047]]    entropy: [array([[-0.4897,  1.2476]])]\n",
      "Loss grads: cce: [[-0.9422 -2.2333]]    entropy: [array([[-0.4825,  1.065 ]])]\n",
      "Loss grads: cce: [[-0.9546 -1.7473]]    entropy: [array([[-0.4759,  0.9409]])]\n",
      "Loss grads: cce: [[-0.9171 -5.3588]]    entropy: [array([[-0.4962,  1.5076]])]\n",
      "Loss grads: cce: [[-0.9168 -5.4583]]    entropy: [array([[-0.4963,  1.5169]])]\n",
      "Loss grads: cce: [[-0.9214 -4.3115]]    entropy: [array([[-0.4938,  1.3977]])]\n",
      "Loss grads: cce: [[-0.925  -3.6971]]    entropy: [array([[-0.4918,  1.3199]])]\n",
      "Loss grads: cce: [[-0.9251 -3.6844]]    entropy: [array([[-0.4918,  1.3182]])]\n",
      "Loss grads: cce: [[-0.9461 -2.0535]]    entropy: [array([[-0.4804,  1.0226]])]\n",
      "Loss grads: cce: [[-0.9231 -3.9932]]    entropy: [array([[-0.4929,  1.3589]])]\n",
      "Loss grads: cce: [[-0.9426 -2.2103]]    entropy: [array([[-0.4823,  1.0598]])]\n",
      "Loss grads: cce: [[-0.9345 -2.7099]]    entropy: [array([[-0.4867,  1.1628]])]\n",
      "Loss grads: cce: [[-0.9294 -3.1623]]    entropy: [array([[-0.4894,  1.2409]])]\n",
      "Loss grads: cce: [[-0.9243 -3.7995]]    entropy: [array([[-0.4922,  1.3337]])]\n",
      "Loss grads: cce: [[-0.9331 -2.819 ]]    entropy: [array([[-0.4874,  1.1828]])]\n",
      "Loss grads: cce: [[-0.9309 -3.0101]]    entropy: [array([[-0.4886,  1.216 ]])]\n",
      "Loss grads: cce: [[-0.9304 -3.0639]]    entropy: [array([[-0.4889,  1.2249]])]\n",
      "Loss grads: cce: [[-0.925  -3.6979]]    entropy: [array([[-0.4918,  1.32  ]])]\n",
      "Loss grads: cce: [[-0.9524 -1.8191]]    entropy: [array([[-0.4771,  0.9613]])]\n",
      "Loss grads: cce: [[-0.935  -2.6738]]    entropy: [array([[-0.4864,  1.1561]])]\n",
      "Loss grads: cce: [[-0.9241 -3.8369]]    entropy: [array([[-0.4923,  1.3387]])]\n",
      "Loss grads: cce: [[-0.9827 -1.1884]]    entropy: [array([[-0.4612,  0.746 ]])]\n",
      "Loss grads: cce: [[-0.93   -3.1044]]    entropy: [array([[-0.4891,  1.2316]])]\n",
      "Loss grads: cce: [[-0.9477 -1.9873]]    entropy: [array([[-0.4796,  1.006 ]])]\n",
      "Loss grads: cce: [[-0.9338 -2.7622]]    entropy: [array([[-0.487 ,  1.1725]])]\n",
      "Loss grads: cce: [[-0.9305 -3.0532]]    entropy: [array([[-0.4888,  1.2231]])]\n",
      "Loss grads: cce: [[-0.9305 -3.0517]]    entropy: [array([[-0.4888,  1.2229]])]\n",
      "Loss grads: cce: [[-0.9736 -1.3227]]    entropy: [array([[-0.4659,  0.8001]])]\n",
      "Loss grads: cce: [[-0.9308 -3.0182]]    entropy: [array([[-0.4887,  1.2173]])]\n",
      "Loss grads: cce: [[-0.9276 -3.3648]]    entropy: [array([[-0.4904,  1.2723]])]\n",
      "Loss grads: cce: [[-0.9589 -1.6288]]    entropy: [array([[-0.4736,  0.9054]])]\n",
      "Loss grads: cce: [[-0.9441 -2.1402]]    entropy: [array([[-0.4815,  1.0435]])]\n",
      "Loss grads: cce: [[-0.9213 -4.3261]]    entropy: [array([[-0.4939,  1.3994]])]\n",
      "Loss grads: cce: [[-0.9235 -3.9307]]    entropy: [array([[-0.4927,  1.3509]])]\n",
      "Loss grads: cce: [[-0.9377 -2.4866]]    entropy: [array([[-0.4849,  1.1193]])]\n",
      "Loss grads: cce: [[-0.9305 -3.0495]]    entropy: [array([[-0.4888,  1.2225]])]\n",
      "Loss grads: cce: [[-0.9255 -3.6299]]    entropy: [array([[-0.4916,  1.3106]])]\n",
      "Loss grads: cce: [[-0.945  -2.1005]]    entropy: [array([[-0.481,  1.034]])]\n",
      "Loss grads: cce: [[-0.9338 -2.7646]]    entropy: [array([[-0.4871,  1.1729]])]\n",
      "Loss grads: cce: [[-0.9286 -3.2519]]    entropy: [array([[-0.4899,  1.255 ]])]\n",
      "Loss grads: cce: [[-0.9299 -3.1109]]    entropy: [array([[-0.4892,  1.2326]])]\n",
      "Loss grads: cce: [[-0.9489 -1.939 ]]    entropy: [array([[-0.4789,  0.9935]])]\n",
      "Loss grads: cce: [[-0.9229 -4.0292]]    entropy: [array([[-0.493 ,  1.3634]])]\n",
      "Loss grads: cce: [[-0.9287 -3.2393]]    entropy: [array([[-0.4898,  1.2531]])]\n",
      "Loss grads: cce: [[-0.9532 -1.7932]]    entropy: [array([[-0.4767,  0.954 ]])]\n",
      "Loss grads: cce: [[-0.9265 -3.4901]]    entropy: [array([[-0.491 ,  1.2908]])]\n",
      "Loss grads: cce: [[-0.9358 -2.6144]]    entropy: [array([[-0.486 ,  1.1447]])]\n",
      "Loss grads: cce: [[-0.919  -4.8414]]    entropy: [array([[-0.4951,  1.4563]])]\n",
      "Loss grads: cce: [[-0.9338 -2.7596]]    entropy: [array([[-0.487,  1.172]])]\n",
      "Loss grads: cce: [[-0.9527 -1.8067]]    entropy: [array([[-0.4769,  0.9578]])]\n",
      "Loss grads: cce: [[-0.9332 -2.807 ]]    entropy: [array([[-0.4873,  1.1806]])]\n",
      "Loss grads: cce: [[-0.93  -3.104]]    entropy: [array([[-0.4891,  1.2315]])]\n",
      "Loss grads: cce: [[-0.9264 -3.5089]]    entropy: [array([[-0.4911,  1.2935]])]\n",
      "Loss grads: cce: [[-0.941  -2.2927]]    entropy: [array([[-0.4831,  1.0783]])]\n",
      "Loss grads: cce: [[-0.9234 -3.9519]]    entropy: [array([[-0.4927,  1.3536]])]\n",
      "Loss grads: cce: [[-0.9325 -2.872 ]]    entropy: [array([[-0.4878,  1.1922]])]\n",
      "Loss grads: cce: [[-0.9496 -1.9161]]    entropy: [array([[-0.4786,  0.9876]])]\n",
      "Loss grads: cce: [[-0.9459 -2.0601]]    entropy: [array([[-0.4805,  1.0242]])]\n",
      "Loss grads: cce: [[-0.9277 -3.3511]]    entropy: [array([[-0.4904,  1.2702]])]\n",
      "Loss grads: cce: [[-0.934  -2.7467]]    entropy: [array([[-0.4869,  1.1696]])]\n",
      "Loss grads: cce: [[-0.9361 -2.5944]]    entropy: [array([[-0.4858,  1.1408]])]\n",
      "Loss grads: cce: [[-0.9244 -3.7857]]    entropy: [array([[-0.4922,  1.3319]])]\n",
      "Loss grads: cce: [[-0.9336 -2.7763]]    entropy: [array([[-0.4871,  1.1751]])]\n",
      "Loss grads: cce: [[-0.9821 -1.1966]]    entropy: [array([[-0.4616,  0.7495]])]\n",
      "Loss grads: cce: [[-0.9378 -2.483 ]]    entropy: [array([[-0.4849,  1.1186]])]\n",
      "Loss grads: cce: [[-0.9491 -1.9324]]    entropy: [array([[-0.4788,  0.9918]])]\n",
      "Loss grads: cce: [[-0.9444 -2.1278]]    entropy: [array([[-0.4813,  1.0405]])]\n",
      "Loss grads: cce: [[-0.9253 -3.6641]]    entropy: [array([[-0.4917,  1.3154]])]\n",
      "Loss grads: cce: [[-0.9421 -2.2403]]    entropy: [array([[-0.4826,  1.0666]])]\n",
      "Loss grads: cce: [[-0.9349 -2.6776]]    entropy: [array([[-0.4864,  1.1568]])]\n",
      "Loss grads: cce: [[-0.9277 -3.3476]]    entropy: [array([[-0.4904,  1.2697]])]\n",
      "Loss grads: cce: [[-0.9343 -2.7253]]    entropy: [array([[-0.4868,  1.1657]])]\n",
      "Loss grads: cce: [[-0.9414 -2.2744]]    entropy: [array([[-0.483 ,  1.0742]])]\n",
      "Loss grads: cce: [[-0.956  -1.7083]]    entropy: [array([[-0.4752,  0.9295]])]\n",
      "Loss grads: cce: [[-0.9255 -3.629 ]]    entropy: [array([[-0.4916,  1.3105]])]\n",
      "Loss grads: cce: [[-0.9301 -3.0923]]    entropy: [array([[-0.4891,  1.2296]])]\n",
      "Loss grads: cce: [[-0.959  -1.6265]]    entropy: [array([[-0.4736,  0.9047]])]\n",
      "Loss grads: cce: [[-0.9345 -2.7103]]    entropy: [array([[-0.4867,  1.1629]])]\n",
      "Loss grads: cce: [[-0.9427 -2.2066]]    entropy: [array([[-0.4822,  1.0589]])]\n",
      "Loss grads: cce: [[-0.941  -2.2934]]    entropy: [array([[-0.4831,  1.0784]])]\n",
      "Loss grads: cce: [[-0.9276 -3.3574]]    entropy: [array([[-0.4904,  1.2712]])]\n",
      "Loss grads: cce: [[-0.9538 -1.7731]]    entropy: [array([[-0.4763,  0.9483]])]\n",
      "Loss grads: cce: [[-0.9404 -2.3284]]    entropy: [array([[-0.4835,  1.0861]])]\n",
      "Loss grads: cce: [[-0.926  -3.5571]]    entropy: [array([[-0.4913,  1.3004]])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss grads: cce: [[-0.9289 -3.2181]]    entropy: [array([[-0.4897,  1.2497]])]\n",
      "Loss grads: cce: [[-0.9221 -4.1686]]    entropy: [array([[-0.4934,  1.3806]])]\n",
      "Loss grads: cce: [[-0.9322 -2.8941]]    entropy: [array([[-0.4879,  1.1961]])]\n",
      "Loss grads: cce: [[-0.9314 -2.9695]]    entropy: [array([[-0.4884,  1.2091]])]\n",
      "Loss grads: cce: [[-0.9302 -3.0834]]    entropy: [array([[-0.489 ,  1.2281]])]\n",
      "Loss grads: cce: [[-0.9321 -2.9006]]    entropy: [array([[-0.4879,  1.1972]])]\n",
      "Loss grads: cce: [[-0.9263 -3.5207]]    entropy: [array([[-0.4911,  1.2952]])]\n",
      "Loss grads: cce: [[-0.9328 -2.8404]]    entropy: [array([[-0.4876,  1.1866]])]\n",
      "Loss grads: cce: [[-0.9465 -2.0356]]    entropy: [array([[-0.4802,  1.0181]])]\n",
      "Loss grads: cce: [[-0.9414 -2.2745]]    entropy: [array([[-0.483 ,  1.0743]])]\n",
      "Loss grads: cce: [[-0.9376 -2.4935]]    entropy: [array([[-0.485 ,  1.1207]])]\n",
      "Loss grads: cce: [[-0.934  -2.7479]]    entropy: [array([[-0.4869,  1.1699]])]\n",
      "Loss grads: cce: [[-0.9491 -1.9317]]    entropy: [array([[-0.4788,  0.9916]])]\n",
      "Loss grads: cce: [[-0.9324 -2.8765]]    entropy: [array([[-0.4878,  1.193 ]])]\n",
      "Loss grads: cce: [[-0.9356 -2.6275]]    entropy: [array([[-0.4861,  1.1472]])]\n",
      "Loss grads: cce: [[-0.9457 -2.0683]]    entropy: [array([[-0.4806,  1.0262]])]\n",
      "Loss grads: cce: [[-0.9245 -3.7702]]    entropy: [array([[-0.4921,  1.3298]])]\n",
      "Loss grads: cce: [[-0.9473 -2.003 ]]    entropy: [array([[-0.4798,  1.01  ]])]\n",
      "Loss grads: cce: [[-0.9319 -2.9181]]    entropy: [array([[-0.4881,  1.2003]])]\n",
      "Loss grads: cce: [[-0.9347 -2.6936]]    entropy: [array([[-0.4866,  1.1598]])]\n",
      "Loss grads: cce: [[-0.9335 -2.7828]]    entropy: [array([[-0.4872,  1.1763]])]\n",
      "Loss grads: cce: [[-0.9393 -2.3912]]    entropy: [array([[-0.4841,  1.0996]])]\n",
      "Loss grads: cce: [[-0.9409 -2.2988]]    entropy: [array([[-0.4832,  1.0796]])]\n",
      "Loss grads: cce: [[-0.9442 -2.1344]]    entropy: [array([[-0.4814,  1.0421]])]\n",
      "Loss grads: cce: [[-0.9374 -2.508 ]]    entropy: [array([[-0.4851,  1.1237]])]\n",
      "Loss grads: cce: [[-0.9353 -2.6525]]    entropy: [array([[-0.4863,  1.152 ]])]\n",
      "Loss grads: cce: [[-0.9285 -3.2599]]    entropy: [array([[-0.4899,  1.2563]])]\n",
      "Loss grads: cce: [[-0.9344 -2.7182]]    entropy: [array([[-0.4867,  1.1644]])]\n",
      "Loss grads: cce: [[-0.9512 -1.8569]]    entropy: [array([[-0.4777,  0.9717]])]\n",
      "Loss grads: cce: [[-0.925  -3.6951]]    entropy: [array([[-0.4918,  1.3196]])]\n",
      "Loss grads: cce: [[-0.9321 -2.9007]]    entropy: [array([[-0.4879,  1.1972]])]\n",
      "Loss grads: cce: [[-0.9342 -2.7351]]    entropy: [array([[-0.4869,  1.1675]])]\n",
      "Loss grads: cce: [[-0.9485 -1.9545]]    entropy: [array([[-0.4791,  0.9976]])]\n",
      "Loss grads: cce: [[-0.9436 -2.1642]]    entropy: [array([[-0.4818,  1.0491]])]\n",
      "Loss grads: cce: [[-0.9351 -2.6674]]    entropy: [array([[-0.4864,  1.1548]])]\n",
      "Loss grads: cce: [[-0.9351 -2.6643]]    entropy: [array([[-0.4863,  1.1542]])]\n",
      "Loss grads: cce: [[-0.9524 -1.818 ]]    entropy: [array([[-0.4771,  0.961 ]])]\n",
      "Loss grads: cce: [[-0.9427 -2.2056]]    entropy: [array([[-0.4822,  1.0587]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5148]]    entropy: [array([[-0.4852,  1.125 ]])]\n",
      "Loss grads: cce: [[-0.9388 -2.4199]]    entropy: [array([[-0.4843,  1.1056]])]\n",
      "Loss grads: cce: [[-0.9448 -2.1076]]    entropy: [array([[-0.4811,  1.0357]])]\n",
      "Loss grads: cce: [[-0.9319 -2.9243]]    entropy: [array([[-0.4881,  1.2013]])]\n",
      "Loss grads: cce: [[-0.9325 -2.8735]]    entropy: [array([[-0.4878,  1.1925]])]\n",
      "Loss grads: cce: [[-0.944  -2.1454]]    entropy: [array([[-0.4816,  1.0447]])]\n",
      "Loss grads: cce: [[-0.9419 -2.2481]]    entropy: [array([[-0.4827,  1.0684]])]\n",
      "Loss grads: cce: [[-0.9319 -2.9202]]    entropy: [array([[-0.4881,  1.2006]])]\n",
      "Loss grads: cce: [[-0.9331 -2.8158]]    entropy: [array([[-0.4874,  1.1822]])]\n",
      "Loss grads: cce: [[-0.9392 -2.3974]]    entropy: [array([[-0.4841,  1.1009]])]\n",
      "Loss grads: cce: [[-0.9304 -3.0631]]    entropy: [array([[-0.4889,  1.2248]])]\n",
      "Loss grads: cce: [[-0.9313 -2.973 ]]    entropy: [array([[-0.4884,  1.2097]])]\n",
      "Loss grads: cce: [[-0.9447 -2.1121]]    entropy: [array([[-0.4812,  1.0368]])]\n",
      "Loss grads: cce: [[-0.9444 -2.1262]]    entropy: [array([[-0.4813,  1.0402]])]\n",
      "Loss grads: cce: [[-0.9316 -2.9514]]    entropy: [array([[-0.4883,  1.206 ]])]\n",
      "Loss grads: cce: [[-0.928  -3.3173]]    entropy: [array([[-0.4902,  1.2651]])]\n",
      "Loss grads: cce: [[-0.9463 -2.0433]]    entropy: [array([[-0.4803,  1.02  ]])]\n",
      "Loss grads: cce: [[-0.9316 -2.9483]]    entropy: [array([[-0.4882,  1.2055]])]\n",
      "Loss grads: cce: [[-0.9433 -2.1808]]    entropy: [array([[-0.482,  1.053]])]\n",
      "Loss grads: cce: [[-0.9445 -2.1214]]    entropy: [array([[-0.4813,  1.039 ]])]\n",
      "Loss grads: cce: [[-0.9339 -2.7544]]    entropy: [array([[-0.487 ,  1.1711]])]\n",
      "Loss grads: cce: [[-0.9331 -2.8165]]    entropy: [array([[-0.4874,  1.1823]])]\n",
      "Loss grads: cce: [[-0.9383 -2.4516]]    entropy: [array([[-0.4846,  1.1122]])]\n",
      "Loss grads: cce: [[-0.9396 -2.3756]]    entropy: [array([[-0.4839,  1.0962]])]\n",
      "Loss grads: cce: [[-0.9322 -2.8947]]    entropy: [array([[-0.4879,  1.1962]])]\n",
      "Loss grads: cce: [[-0.9403 -2.3335]]    entropy: [array([[-0.4835,  1.0872]])]\n",
      "Loss grads: cce: [[-0.9398 -2.3624]]    entropy: [array([[-0.4838,  1.0934]])]\n",
      "Loss grads: cce: [[-0.9316 -2.9481]]    entropy: [array([[-0.4882,  1.2054]])]\n",
      "Loss grads: cce: [[-0.9316 -2.9487]]    entropy: [array([[-0.4882,  1.2055]])]\n",
      "Loss grads: cce: [[-0.9388 -2.4224]]    entropy: [array([[-0.4844,  1.1061]])]\n",
      "Loss grads: cce: [[-0.9353 -2.653 ]]    entropy: [array([[-0.4863,  1.1521]])]\n",
      "Loss grads: cce: [[-0.9394 -2.3842]]    entropy: [array([[-0.484 ,  1.0981]])]\n",
      "Loss grads: cce: [[-0.9406 -2.3149]]    entropy: [array([[-0.4834,  1.0832]])]\n",
      "Loss grads: cce: [[-0.9288 -3.2297]]    entropy: [array([[-0.4898,  1.2516]])]\n",
      "Loss grads: cce: [[-0.946  -2.0583]]    entropy: [array([[-0.4805,  1.0237]])]\n",
      "Loss grads: cce: [[-0.945  -2.0981]]    entropy: [array([[-0.481 ,  1.0334]])]\n",
      "Loss grads: cce: [[-0.9386 -2.4294]]    entropy: [array([[-0.4844,  1.1076]])]\n",
      "Loss grads: cce: [[-0.9381 -2.4646]]    entropy: [array([[-0.4847,  1.1149]])]\n",
      "Loss grads: cce: [[-0.939  -2.4051]]    entropy: [array([[-0.4842,  1.1025]])]\n",
      "Loss grads: cce: [[-0.9343 -2.722 ]]    entropy: [array([[-0.4868,  1.1651]])]\n",
      "Loss grads: cce: [[-0.937  -2.5357]]    entropy: [array([[-0.4853,  1.1292]])]\n",
      "Loss grads: cce: [[-0.9354 -2.6428]]    entropy: [array([[-0.4862,  1.1502]])]\n",
      "Loss grads: cce: [[-0.9335 -2.7881]]    entropy: [array([[-0.4872,  1.1772]])]\n",
      "Loss grads: cce: [[-0.9428 -2.2033]]    entropy: [array([[-0.4822,  1.0582]])]\n",
      "Loss grads: cce: [[-0.9391 -2.4001]]    entropy: [array([[-0.4842,  1.1014]])]\n",
      "Loss grads: cce: [[-0.942  -2.2412]]    entropy: [array([[-0.4826,  1.0668]])]\n",
      "Loss grads: cce: [[-0.9384 -2.4458]]    entropy: [array([[-0.4846,  1.111 ]])]\n",
      "Loss grads: cce: [[-0.9399 -2.3579]]    entropy: [array([[-0.4838,  1.0925]])]\n",
      "Loss grads: cce: [[-0.9395 -2.3756]]    entropy: [array([[-0.4839,  1.0963]])]\n",
      "Loss grads: cce: [[-0.9402 -2.3403]]    entropy: [array([[-0.4836,  1.0887]])]\n",
      "Loss grads: cce: [[-0.9349 -2.6802]]    entropy: [array([[-0.4865,  1.1573]])]\n",
      "Loss grads: cce: [[-0.9355 -2.6322]]    entropy: [array([[-0.4861,  1.1481]])]\n",
      "Loss grads: cce: [[-0.9423 -2.2259]]    entropy: [array([[-0.4824,  1.0633]])]\n",
      "Loss grads: cce: [[-0.9353 -2.6505]]    entropy: [array([[-0.4862,  1.1516]])]\n",
      "Loss grads: cce: [[-0.9414 -2.2753]]    entropy: [array([[-0.483 ,  1.0744]])]\n",
      "Loss grads: cce: [[-0.939  -2.4104]]    entropy: [array([[-0.4843,  1.1036]])]\n",
      "Loss grads: cce: [[-0.934  -2.7495]]    entropy: [array([[-0.487 ,  1.1702]])]\n",
      "Loss grads: cce: [[-0.9372 -2.522 ]]    entropy: [array([[-0.4852,  1.1265]])]\n",
      "Loss grads: cce: [[-0.9338 -2.7625]]    entropy: [array([[-0.487 ,  1.1726]])]\n",
      "Loss grads: cce: [[-0.9387 -2.4283]]    entropy: [array([[-0.4844,  1.1073]])]\n",
      "Loss grads: cce: [[-0.9355 -2.6372]]    entropy: [array([[-0.4861,  1.1491]])]\n",
      "Loss grads: cce: [[-0.9393 -2.3879]]    entropy: [array([[-0.4841,  1.0989]])]\n",
      "Loss grads: cce: [[-0.941  -2.2965]]    entropy: [array([[-0.4832,  1.0791]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5581]]    entropy: [array([[-0.4855,  1.1337]])]\n",
      "Loss grads: cce: [[-0.9366 -2.562 ]]    entropy: [array([[-0.4856,  1.1344]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5592]]    entropy: [array([[-0.4855,  1.1339]])]\n",
      "Loss grads: cce: [[-0.9422 -2.2334]]    entropy: [array([[-0.4825,  1.065 ]])]\n",
      "Loss grads: cce: [[-0.9326 -2.8587]]    entropy: [array([[-0.4877,  1.1899]])]\n",
      "Loss grads: cce: [[-0.9388 -2.4223]]    entropy: [array([[-0.4844,  1.1061]])]\n",
      "Loss grads: cce: [[-0.9336 -2.7755]]    entropy: [array([[-0.4871,  1.1749]])]\n",
      "Loss grads: cce: [[-0.9361 -2.5905]]    entropy: [array([[-0.4858,  1.14  ]])]\n",
      "Loss grads: cce: [[-0.9362 -2.5861]]    entropy: [array([[-0.4857,  1.1392]])]\n",
      "Loss grads: cce: [[-0.9325 -2.865 ]]    entropy: [array([[-0.4877,  1.191 ]])]\n",
      "Loss grads: cce: [[-0.9406 -2.3182]]    entropy: [array([[-0.4834,  1.0839]])]\n",
      "Loss grads: cce: [[-0.9369 -2.542 ]]    entropy: [array([[-0.4854,  1.1305]])]\n",
      "Loss grads: cce: [[-0.9323 -2.8872]]    entropy: [array([[-0.4879,  1.1949]])]\n",
      "Loss grads: cce: [[-0.9416 -2.2639]]    entropy: [array([[-0.4828,  1.0719]])]\n",
      "Loss grads: cce: [[-0.937  -2.5304]]    entropy: [array([[-0.4853,  1.1282]])]\n",
      "Loss grads: cce: [[-0.9379 -2.4763]]    entropy: [array([[-0.4848,  1.1172]])]\n",
      "Loss grads: cce: [[-0.9377 -2.487 ]]    entropy: [array([[-0.4849,  1.1194]])]\n",
      "Loss grads: cce: [[-0.9285 -3.2623]]    entropy: [array([[-0.4899,  1.2566]])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss grads: cce: [[-0.9356 -2.6253]]    entropy: [array([[-0.486 ,  1.1468]])]\n",
      "Loss grads: cce: [[-0.9331 -2.8172]]    entropy: [array([[-0.4874,  1.1825]])]\n",
      "Loss grads: cce: [[-0.9381 -2.4592]]    entropy: [array([[-0.4847,  1.1137]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5398]]    entropy: [array([[-0.4854,  1.13  ]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5491]]    entropy: [array([[-0.4855,  1.1319]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5168]]    entropy: [array([[-0.4852,  1.1255]])]\n",
      "Loss grads: cce: [[-0.937  -2.5318]]    entropy: [array([[-0.4853,  1.1285]])]\n",
      "Loss grads: cce: [[-0.9398 -2.3617]]    entropy: [array([[-0.4838,  1.0933]])]\n",
      "Loss grads: cce: [[-0.9345 -2.7121]]    entropy: [array([[-0.4867,  1.1632]])]\n",
      "Loss grads: cce: [[-0.9406 -2.3153]]    entropy: [array([[-0.4834,  1.0833]])]\n",
      "Loss grads: cce: [[-0.9411 -2.2902]]    entropy: [array([[-0.4831,  1.0777]])]\n",
      "Loss grads: cce: [[-0.9358 -2.6122]]    entropy: [array([[-0.4859,  1.1443]])]\n",
      "Loss grads: cce: [[-0.9377 -2.4904]]    entropy: [array([[-0.485 ,  1.1201]])]\n",
      "Loss grads: cce: [[-0.9364 -2.5733]]    entropy: [array([[-0.4856,  1.1367]])]\n",
      "Loss grads: cce: [[-0.9377 -2.486 ]]    entropy: [array([[-0.4849,  1.1192]])]\n",
      "Loss grads: cce: [[-0.9315 -2.9542]]    entropy: [array([[-0.4883,  1.2065]])]\n",
      "Loss grads: cce: [[-0.9406 -2.3161]]    entropy: [array([[-0.4834,  1.0834]])]\n",
      "Loss grads: cce: [[-0.936  -2.5983]]    entropy: [array([[-0.4858,  1.1416]])]\n",
      "Loss grads: cce: [[-0.9413 -2.2776]]    entropy: [array([[-0.483 ,  1.0749]])]\n",
      "Loss grads: cce: [[-0.9357 -2.6199]]    entropy: [array([[-0.486 ,  1.1458]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5398]]    entropy: [array([[-0.4854,  1.1301]])]\n",
      "Loss grads: cce: [[-0.9398 -2.36  ]]    entropy: [array([[-0.4838,  1.0929]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4787]]    entropy: [array([[-0.4849,  1.1177]])]\n",
      "Loss grads: cce: [[-0.942  -2.2427]]    entropy: [array([[-0.4826,  1.0671]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5678]]    entropy: [array([[-0.4856,  1.1356]])]\n",
      "Loss grads: cce: [[-0.94   -2.3472]]    entropy: [array([[-0.4837,  1.0902]])]\n",
      "Loss grads: cce: [[-0.9394 -2.3855]]    entropy: [array([[-0.484 ,  1.0983]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5183]]    entropy: [array([[-0.4852,  1.1257]])]\n",
      "Loss grads: cce: [[-0.9383 -2.4493]]    entropy: [array([[-0.4846,  1.1117]])]\n",
      "Loss grads: cce: [[-0.9359 -2.605 ]]    entropy: [array([[-0.4859,  1.1429]])]\n",
      "Loss grads: cce: [[-0.9327 -2.8529]]    entropy: [array([[-0.4876,  1.1888]])]\n",
      "Loss grads: cce: [[-0.936  -2.5976]]    entropy: [array([[-0.4858,  1.1414]])]\n",
      "Loss grads: cce: [[-0.9393 -2.3876]]    entropy: [array([[-0.4841,  1.0988]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5592]]    entropy: [array([[-0.4855,  1.1339]])]\n",
      "Loss grads: cce: [[-0.9355 -2.6342]]    entropy: [array([[-0.4861,  1.1485]])]\n",
      "Loss grads: cce: [[-0.9381 -2.4615]]    entropy: [array([[-0.4847,  1.1142]])]\n",
      "Loss grads: cce: [[-0.9379 -2.4763]]    entropy: [array([[-0.4848,  1.1172]])]\n",
      "Loss grads: cce: [[-0.9383 -2.4512]]    entropy: [array([[-0.4846,  1.1121]])]\n",
      "Loss grads: cce: [[-0.9318 -2.9325]]    entropy: [array([[-0.4881,  1.2028]])]\n",
      "Loss grads: cce: [[-0.9408 -2.3057]]    entropy: [array([[-0.4833,  1.0812]])]\n",
      "Loss grads: cce: [[-0.9389 -2.4122]]    entropy: [array([[-0.4843,  1.104 ]])]\n",
      "Loss grads: cce: [[-0.9387 -2.4248]]    entropy: [array([[-0.4844,  1.1066]])]\n",
      "Loss grads: cce: [[-0.9388 -2.4201]]    entropy: [array([[-0.4843,  1.1056]])]\n",
      "Loss grads: cce: [[-0.9351 -2.6647]]    entropy: [array([[-0.4863,  1.1543]])]\n",
      "Loss grads: cce: [[-0.9379 -2.4737]]    entropy: [array([[-0.4848,  1.1167]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4828]]    entropy: [array([[-0.4849,  1.1186]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5101]]    entropy: [array([[-0.4851,  1.1241]])]\n",
      "Loss grads: cce: [[-0.9328 -2.8455]]    entropy: [array([[-0.4876,  1.1875]])]\n",
      "Loss grads: cce: [[-0.9388 -2.4225]]    entropy: [array([[-0.4844,  1.1061]])]\n",
      "Loss grads: cce: [[-0.9301 -3.0911]]    entropy: [array([[-0.4891,  1.2294]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5068]]    entropy: [array([[-0.4851,  1.1234]])]\n",
      "Loss grads: cce: [[-0.9382 -2.4539]]    entropy: [array([[-0.4846,  1.1126]])]\n",
      "Loss grads: cce: [[-0.935  -2.6749]]    entropy: [array([[-0.4864,  1.1563]])]\n",
      "Loss grads: cce: [[-0.9402 -2.3408]]    entropy: [array([[-0.4836,  1.0888]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5481]]    entropy: [array([[-0.4854,  1.1317]])]\n",
      "Loss grads: cce: [[-0.9332 -2.8123]]    entropy: [array([[-0.4874,  1.1816]])]\n",
      "Loss grads: cce: [[-0.9382 -2.453 ]]    entropy: [array([[-0.4846,  1.1125]])]\n",
      "Loss grads: cce: [[-0.9384 -2.4465]]    entropy: [array([[-0.4846,  1.1111]])]\n",
      "Loss grads: cce: [[-0.933  -2.8258]]    entropy: [array([[-0.4875,  1.184 ]])]\n",
      "Loss grads: cce: [[-0.9392 -2.3939]]    entropy: [array([[-0.4841,  1.1001]])]\n",
      "Loss grads: cce: [[-0.9386 -2.4331]]    entropy: [array([[-0.4845,  1.1083]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4816]]    entropy: [array([[-0.4849,  1.1183]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5549]]    entropy: [array([[-0.4855,  1.133 ]])]\n",
      "Loss grads: cce: [[-0.9349 -2.6753]]    entropy: [array([[-0.4864,  1.1563]])]\n",
      "Loss grads: cce: [[-0.9379 -2.4771]]    entropy: [array([[-0.4849,  1.1174]])]\n",
      "Loss grads: cce: [[-0.9343 -2.723 ]]    entropy: [array([[-0.4868,  1.1653]])]\n",
      "Loss grads: cce: [[-0.9361 -2.5946]]    entropy: [array([[-0.4858,  1.1408]])]\n",
      "Loss grads: cce: [[-0.935  -2.6746]]    entropy: [array([[-0.4864,  1.1562]])]\n",
      "Loss grads: cce: [[-0.9349 -2.6806]]    entropy: [array([[-0.4865,  1.1573]])]\n",
      "Loss grads: cce: [[-0.9377 -2.4853]]    entropy: [array([[-0.4849,  1.1191]])]\n",
      "Loss grads: cce: [[-0.938  -2.4663]]    entropy: [array([[-0.4848,  1.1152]])]\n",
      "Loss grads: cce: [[-0.9358 -2.6165]]    entropy: [array([[-0.486 ,  1.1451]])]\n",
      "Loss grads: cce: [[-0.9353 -2.646 ]]    entropy: [array([[-0.4862,  1.1508]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4829]]    entropy: [array([[-0.4849,  1.1186]])]\n",
      "Loss grads: cce: [[-0.937  -2.5322]]    entropy: [array([[-0.4853,  1.1285]])]\n",
      "Loss grads: cce: [[-0.9324 -2.8753]]    entropy: [array([[-0.4878,  1.1928]])]\n",
      "Loss grads: cce: [[-0.9345 -2.7088]]    entropy: [array([[-0.4867,  1.1626]])]\n",
      "Loss grads: cce: [[-0.9405 -2.3199]]    entropy: [array([[-0.4834,  1.0843]])]\n",
      "Loss grads: cce: [[-0.934  -2.7464]]    entropy: [array([[-0.4869,  1.1696]])]\n",
      "Loss grads: cce: [[-0.9341 -2.7366]]    entropy: [array([[-0.4869,  1.1678]])]\n",
      "Loss grads: cce: [[-0.9388 -2.4202]]    entropy: [array([[-0.4843,  1.1057]])]\n",
      "Loss grads: cce: [[-0.9338 -2.764 ]]    entropy: [array([[-0.4871,  1.1728]])]\n",
      "Loss grads: cce: [[-0.9392 -2.3946]]    entropy: [array([[-0.4841,  1.1003]])]\n",
      "Loss grads: cce: [[-0.939  -2.4098]]    entropy: [array([[-0.4843,  1.1035]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5661]]    entropy: [array([[-0.4856,  1.1353]])]\n",
      "Loss grads: cce: [[-0.9363 -2.5798]]    entropy: [array([[-0.4857,  1.1379]])]\n",
      "Loss grads: cce: [[-0.9335 -2.7881]]    entropy: [array([[-0.4872,  1.1772]])]\n",
      "Loss grads: cce: [[-0.9387 -2.4255]]    entropy: [array([[-0.4844,  1.1068]])]\n",
      "Loss grads: cce: [[-0.9329 -2.837 ]]    entropy: [array([[-0.4875,  1.186 ]])]\n",
      "Loss grads: cce: [[-0.938  -2.4689]]    entropy: [array([[-0.4848,  1.1157]])]\n",
      "Loss grads: cce: [[-0.9387 -2.4241]]    entropy: [array([[-0.4844,  1.1065]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5236]]    entropy: [array([[-0.4852,  1.1268]])]\n",
      "Loss grads: cce: [[-0.9384 -2.4439]]    entropy: [array([[-0.4846,  1.1106]])]\n",
      "Loss grads: cce: [[-0.9382 -2.4547]]    entropy: [array([[-0.4847,  1.1128]])]\n",
      "Loss grads: cce: [[-0.9396 -2.3726]]    entropy: [array([[-0.4839,  1.0956]])]\n",
      "Loss grads: cce: [[-0.9385 -2.438 ]]    entropy: [array([[-0.4845,  1.1094]])]\n",
      "Loss grads: cce: [[-0.9381 -2.4635]]    entropy: [array([[-0.4847,  1.1146]])]\n",
      "Loss grads: cce: [[-0.9364 -2.5696]]    entropy: [array([[-0.4856,  1.1359]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5641]]    entropy: [array([[-0.4856,  1.1349]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5462]]    entropy: [array([[-0.4854,  1.1313]])]\n",
      "Loss grads: cce: [[-0.9351 -2.6649]]    entropy: [array([[-0.4863,  1.1544]])]\n",
      "Loss grads: cce: [[-0.9321 -2.9013]]    entropy: [array([[-0.488 ,  1.1973]])]\n",
      "Loss grads: cce: [[-0.9351 -2.6651]]    entropy: [array([[-0.4863,  1.1544]])]\n",
      "Loss grads: cce: [[-0.9417 -2.2558]]    entropy: [array([[-0.4828,  1.0701]])]\n",
      "Loss grads: cce: [[-0.9342 -2.7279]]    entropy: [array([[-0.4868,  1.1662]])]\n",
      "Loss grads: cce: [[-0.9393 -2.3925]]    entropy: [array([[-0.4841,  1.0998]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5513]]    entropy: [array([[-0.4855,  1.1323]])]\n",
      "Loss grads: cce: [[-0.9355 -2.634 ]]    entropy: [array([[-0.4861,  1.1485]])]\n",
      "Loss grads: cce: [[-0.9379 -2.4732]]    entropy: [array([[-0.4848,  1.1166]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5627]]    entropy: [array([[-0.4856,  1.1346]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5278]]    entropy: [array([[-0.4853,  1.1277]])]\n",
      "Loss grads: cce: [[-0.937  -2.5304]]    entropy: [array([[-0.4853,  1.1282]])]\n",
      "Loss grads: cce: [[-0.9367 -2.551 ]]    entropy: [array([[-0.4855,  1.1323]])]\n",
      "Loss grads: cce: [[-0.9383 -2.4506]]    entropy: [array([[-0.4846,  1.112 ]])]\n",
      "Loss grads: cce: [[-0.9375 -2.5   ]]    entropy: [array([[-0.485 ,  1.1221]])]\n",
      "Loss grads: cce: [[-0.9382 -2.4574]]    entropy: [array([[-0.4847,  1.1134]])]\n",
      "Loss grads: cce: [[-0.9336 -2.7769]]    entropy: [array([[-0.4871,  1.1752]])]\n",
      "Loss grads: cce: [[-0.9346 -2.7046]]    entropy: [array([[-0.4866,  1.1618]])]\n",
      "Loss grads: cce: [[-0.9384 -2.4414]]    entropy: [array([[-0.4845,  1.1101]])]\n",
      "Loss grads: cce: [[-0.9339 -2.7562]]    entropy: [array([[-0.487 ,  1.1714]])]\n",
      "Loss grads: cce: [[-0.9332 -2.8125]]    entropy: [array([[-0.4874,  1.1816]])]\n",
      "Loss grads: cce: [[-0.9379 -2.477 ]]    entropy: [array([[-0.4848,  1.1174]])]\n",
      "Loss grads: cce: [[-0.9347 -2.6914]]    entropy: [array([[-0.4865,  1.1594]])]\n",
      "Loss grads: cce: [[-0.937  -2.5336]]    entropy: [array([[-0.4853,  1.1288]])]\n",
      "Loss grads: cce: [[-0.937  -2.5326]]    entropy: [array([[-0.4853,  1.1286]])]\n",
      "Loss grads: cce: [[-0.9355 -2.6374]]    entropy: [array([[-0.4861,  1.1491]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5419]]    entropy: [array([[-0.4854,  1.1305]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5374]]    entropy: [array([[-0.4854,  1.1296]])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss grads: cce: [[-0.9372 -2.5223]]    entropy: [array([[-0.4852,  1.1265]])]\n",
      "Loss grads: cce: [[-0.9389 -2.4154]]    entropy: [array([[-0.4843,  1.1046]])]\n",
      "Loss grads: cce: [[-0.9358 -2.6111]]    entropy: [array([[-0.4859,  1.144 ]])]\n",
      "Loss grads: cce: [[-0.9386 -2.4331]]    entropy: [array([[-0.4845,  1.1083]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5186]]    entropy: [array([[-0.4852,  1.1258]])]\n",
      "Loss grads: cce: [[-0.9379 -2.4719]]    entropy: [array([[-0.4848,  1.1163]])]\n",
      "Loss grads: cce: [[-0.9363 -2.5778]]    entropy: [array([[-0.4857,  1.1376]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5512]]    entropy: [array([[-0.4855,  1.1323]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5221]]    entropy: [array([[-0.4852,  1.1265]])]\n",
      "Loss grads: cce: [[-0.9381 -2.4635]]    entropy: [array([[-0.4847,  1.1146]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4797]]    entropy: [array([[-0.4849,  1.1179]])]\n",
      "Loss grads: cce: [[-0.9357 -2.6184]]    entropy: [array([[-0.486 ,  1.1455]])]\n",
      "Loss grads: cce: [[-0.9383 -2.447 ]]    entropy: [array([[-0.4846,  1.1112]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4814]]    entropy: [array([[-0.4849,  1.1183]])]\n",
      "Loss grads: cce: [[-0.9364 -2.5716]]    entropy: [array([[-0.4856,  1.1363]])]\n",
      "Loss grads: cce: [[-0.9338 -2.7632]]    entropy: [array([[-0.487 ,  1.1727]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5547]]    entropy: [array([[-0.4855,  1.133 ]])]\n",
      "Loss grads: cce: [[-0.9376 -2.4935]]    entropy: [array([[-0.485 ,  1.1207]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5423]]    entropy: [array([[-0.4854,  1.1305]])]\n",
      "Loss grads: cce: [[-0.9397 -2.3642]]    entropy: [array([[-0.4838,  1.0938]])]\n",
      "Loss grads: cce: [[-0.9337 -2.7671]]    entropy: [array([[-0.4871,  1.1734]])]\n",
      "Loss grads: cce: [[-0.9377 -2.4866]]    entropy: [array([[-0.4849,  1.1193]])]\n",
      "Loss grads: cce: [[-0.9383 -2.4512]]    entropy: [array([[-0.4846,  1.1121]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5679]]    entropy: [array([[-0.4856,  1.1356]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5427]]    entropy: [array([[-0.4854,  1.1306]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5074]]    entropy: [array([[-0.4851,  1.1236]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5153]]    entropy: [array([[-0.4852,  1.1251]])]\n",
      "Loss grads: cce: [[-0.9362 -2.5848]]    entropy: [array([[-0.4857,  1.1389]])]\n",
      "Loss grads: cce: [[-0.938  -2.4675]]    entropy: [array([[-0.4848,  1.1154]])]\n",
      "Loss grads: cce: [[-0.936  -2.5986]]    entropy: [array([[-0.4858,  1.1416]])]\n",
      "Loss grads: cce: [[-0.9379 -2.4755]]    entropy: [array([[-0.4848,  1.1171]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5213]]    entropy: [array([[-0.4852,  1.1263]])]\n",
      "Loss grads: cce: [[-0.936  -2.5966]]    entropy: [array([[-0.4858,  1.1412]])]\n",
      "Loss grads: cce: [[-0.9386 -2.4295]]    entropy: [array([[-0.4844,  1.1076]])]\n",
      "Loss grads: cce: [[-0.9362 -2.584 ]]    entropy: [array([[-0.4857,  1.1388]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5258]]    entropy: [array([[-0.4853,  1.1272]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5515]]    entropy: [array([[-0.4855,  1.1324]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4798]]    entropy: [array([[-0.4849,  1.118 ]])]\n",
      "Loss grads: cce: [[-0.9379 -2.476 ]]    entropy: [array([[-0.4848,  1.1172]])]\n",
      "Loss grads: cce: [[-0.9368 -2.547 ]]    entropy: [array([[-0.4854,  1.1315]])]\n",
      "Loss grads: cce: [[-0.937  -2.5309]]    entropy: [array([[-0.4853,  1.1283]])]\n",
      "Loss grads: cce: [[-0.9384 -2.4436]]    entropy: [array([[-0.4846,  1.1105]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5275]]    entropy: [array([[-0.4853,  1.1276]])]\n",
      "Loss grads: cce: [[-0.9384 -2.4426]]    entropy: [array([[-0.4845,  1.1103]])]\n",
      "Loss grads: cce: [[-0.9378 -2.484 ]]    entropy: [array([[-0.4849,  1.1188]])]\n",
      "Loss grads: cce: [[-0.9353 -2.6505]]    entropy: [array([[-0.4862,  1.1516]])]\n",
      "Loss grads: cce: [[-0.9381 -2.4598]]    entropy: [array([[-0.4847,  1.1139]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4826]]    entropy: [array([[-0.4849,  1.1185]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5541]]    entropy: [array([[-0.4855,  1.1329]])]\n",
      "Loss grads: cce: [[-0.937  -2.5332]]    entropy: [array([[-0.4853,  1.1287]])]\n",
      "Loss grads: cce: [[-0.938  -2.4713]]    entropy: [array([[-0.4848,  1.1162]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4794]]    entropy: [array([[-0.4849,  1.1179]])]\n",
      "Loss grads: cce: [[-0.9352 -2.6585]]    entropy: [array([[-0.4863,  1.1532]])]\n",
      "Loss grads: cce: [[-0.9362 -2.5868]]    entropy: [array([[-0.4858,  1.1393]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5523]]    entropy: [array([[-0.4855,  1.1325]])]\n",
      "Loss grads: cce: [[-0.9362 -2.5852]]    entropy: [array([[-0.4857,  1.139 ]])]\n",
      "Loss grads: cce: [[-0.9344 -2.7145]]    entropy: [array([[-0.4867,  1.1637]])]\n",
      "Loss grads: cce: [[-0.9382 -2.458 ]]    entropy: [array([[-0.4847,  1.1135]])]\n",
      "Loss grads: cce: [[-0.935  -2.6705]]    entropy: [array([[-0.4864,  1.1554]])]\n",
      "Loss grads: cce: [[-0.9382 -2.4546]]    entropy: [array([[-0.4847,  1.1128]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5257]]    entropy: [array([[-0.4853,  1.1272]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5611]]    entropy: [array([[-0.4855,  1.1343]])]\n",
      "Loss grads: cce: [[-0.9362 -2.5847]]    entropy: [array([[-0.4857,  1.1389]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5251]]    entropy: [array([[-0.4853,  1.1271]])]\n",
      "Loss grads: cce: [[-0.9332 -2.8117]]    entropy: [array([[-0.4874,  1.1815]])]\n",
      "Loss grads: cce: [[-0.938  -2.4694]]    entropy: [array([[-0.4848,  1.1158]])]\n",
      "Loss grads: cce: [[-0.9355 -2.6318]]    entropy: [array([[-0.4861,  1.148 ]])]\n",
      "Loss grads: cce: [[-0.9384 -2.441 ]]    entropy: [array([[-0.4845,  1.11  ]])]\n",
      "Loss grads: cce: [[-0.9352 -2.6536]]    entropy: [array([[-0.4863,  1.1522]])]\n",
      "Loss grads: cce: [[-0.9377 -2.4881]]    entropy: [array([[-0.4849,  1.1197]])]\n",
      "Loss grads: cce: [[-0.9324 -2.8737]]    entropy: [array([[-0.4878,  1.1925]])]\n",
      "Loss grads: cce: [[-0.9382 -2.4582]]    entropy: [array([[-0.4847,  1.1135]])]\n",
      "Loss grads: cce: [[-0.9386 -2.4344]]    entropy: [array([[-0.4845,  1.1086]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5635]]    entropy: [array([[-0.4856,  1.1347]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4838]]    entropy: [array([[-0.4849,  1.1188]])]\n",
      "Loss grads: cce: [[-0.9338 -2.7615]]    entropy: [array([[-0.487 ,  1.1724]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5275]]    entropy: [array([[-0.4853,  1.1276]])]\n",
      "Loss grads: cce: [[-0.9323 -2.8901]]    entropy: [array([[-0.4879,  1.1954]])]\n",
      "Loss grads: cce: [[-0.9352 -2.6543]]    entropy: [array([[-0.4863,  1.1523]])]\n",
      "Loss grads: cce: [[-0.9395 -2.3777]]    entropy: [array([[-0.484 ,  1.0967]])]\n",
      "Loss grads: cce: [[-0.9381 -2.462 ]]    entropy: [array([[-0.4847,  1.1143]])]\n",
      "Loss grads: cce: [[-0.9382 -2.4581]]    entropy: [array([[-0.4847,  1.1135]])]\n",
      "Loss grads: cce: [[-0.9375 -2.503 ]]    entropy: [array([[-0.4851,  1.1227]])]\n",
      "Loss grads: cce: [[-0.9336 -2.7763]]    entropy: [array([[-0.4871,  1.1751]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5565]]    entropy: [array([[-0.4855,  1.1334]])]\n",
      "Loss grads: cce: [[-0.9357 -2.623 ]]    entropy: [array([[-0.486 ,  1.1463]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5523]]    entropy: [array([[-0.4855,  1.1325]])]\n",
      "Loss grads: cce: [[-0.9378 -2.48  ]]    entropy: [array([[-0.4849,  1.118 ]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4779]]    entropy: [array([[-0.4849,  1.1176]])]\n",
      "Loss grads: cce: [[-0.9381 -2.4615]]    entropy: [array([[-0.4847,  1.1142]])]\n",
      "Loss grads: cce: [[-0.9377 -2.4858]]    entropy: [array([[-0.4849,  1.1192]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5242]]    entropy: [array([[-0.4852,  1.1269]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5141]]    entropy: [array([[-0.4852,  1.1249]])]\n",
      "Loss grads: cce: [[-0.938  -2.4658]]    entropy: [array([[-0.4848,  1.1151]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5128]]    entropy: [array([[-0.4852,  1.1246]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5174]]    entropy: [array([[-0.4852,  1.1256]])]\n",
      "Loss grads: cce: [[-0.9381 -2.4611]]    entropy: [array([[-0.4847,  1.1141]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5038]]    entropy: [array([[-0.4851,  1.1228]])]\n",
      "Loss grads: cce: [[-0.9359 -2.6065]]    entropy: [array([[-0.4859,  1.1432]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5549]]    entropy: [array([[-0.4855,  1.133 ]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5194]]    entropy: [array([[-0.4852,  1.126 ]])]\n",
      "Loss grads: cce: [[-0.9355 -2.6349]]    entropy: [array([[-0.4861,  1.1486]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5583]]    entropy: [array([[-0.4855,  1.1337]])]\n",
      "Loss grads: cce: [[-0.9375 -2.4982]]    entropy: [array([[-0.485 ,  1.1217]])]\n",
      "Loss grads: cce: [[-0.9384 -2.4432]]    entropy: [array([[-0.4846,  1.1104]])]\n",
      "Loss grads: cce: [[-0.9386 -2.4328]]    entropy: [array([[-0.4845,  1.1083]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5538]]    entropy: [array([[-0.4855,  1.1328]])]\n",
      "Loss grads: cce: [[-0.9378 -2.479 ]]    entropy: [array([[-0.4849,  1.1178]])]\n",
      "Loss grads: cce: [[-0.9333 -2.8056]]    entropy: [array([[-0.4873,  1.1804]])]\n",
      "Loss grads: cce: [[-0.9386 -2.4327]]    entropy: [array([[-0.4845,  1.1083]])]\n",
      "Loss grads: cce: [[-0.937  -2.5331]]    entropy: [array([[-0.4853,  1.1287]])]\n",
      "Loss grads: cce: [[-0.9352 -2.654 ]]    entropy: [array([[-0.4863,  1.1523]])]\n",
      "Loss grads: cce: [[-0.9376 -2.4927]]    entropy: [array([[-0.485 ,  1.1206]])]\n",
      "Loss grads: cce: [[-0.936  -2.6022]]    entropy: [array([[-0.4859,  1.1423]])]\n",
      "Loss grads: cce: [[-0.9375 -2.4977]]    entropy: [array([[-0.485 ,  1.1216]])]\n",
      "Loss grads: cce: [[-0.9382 -2.4556]]    entropy: [array([[-0.4847,  1.113 ]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5138]]    entropy: [array([[-0.4852,  1.1248]])]\n",
      "Loss grads: cce: [[-0.9344 -2.7171]]    entropy: [array([[-0.4867,  1.1642]])]\n",
      "Loss grads: cce: [[-0.9384 -2.4466]]    entropy: [array([[-0.4846,  1.1111]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5515]]    entropy: [array([[-0.4855,  1.1324]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5156]]    entropy: [array([[-0.4852,  1.1252]])]\n",
      "Loss grads: cce: [[-0.9381 -2.4645]]    entropy: [array([[-0.4847,  1.1148]])]\n",
      "Loss grads: cce: [[-0.9379 -2.4737]]    entropy: [array([[-0.4848,  1.1167]])]\n",
      "Loss grads: cce: [[-0.935  -2.6681]]    entropy: [array([[-0.4864,  1.155 ]])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss grads: cce: [[-0.9373 -2.5125]]    entropy: [array([[-0.4852,  1.1246]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5084]]    entropy: [array([[-0.4851,  1.1238]])]\n",
      "Loss grads: cce: [[-0.9379 -2.4737]]    entropy: [array([[-0.4848,  1.1167]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5037]]    entropy: [array([[-0.4851,  1.1228]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5145]]    entropy: [array([[-0.4852,  1.125 ]])]\n",
      "Loss grads: cce: [[-0.9376 -2.4961]]    entropy: [array([[-0.485 ,  1.1213]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5682]]    entropy: [array([[-0.4856,  1.1357]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5614]]    entropy: [array([[-0.4856,  1.1343]])]\n",
      "Loss grads: cce: [[-0.9362 -2.5829]]    entropy: [array([[-0.4857,  1.1386]])]\n",
      "Loss grads: cce: [[-0.9361 -2.5916]]    entropy: [array([[-0.4858,  1.1402]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5661]]    entropy: [array([[-0.4856,  1.1353]])]\n",
      "Loss grads: cce: [[-0.9344 -2.7163]]    entropy: [array([[-0.4867,  1.164 ]])]\n",
      "Loss grads: cce: [[-0.937  -2.5353]]    entropy: [array([[-0.4853,  1.1292]])]\n",
      "Loss grads: cce: [[-0.9331 -2.8172]]    entropy: [array([[-0.4874,  1.1825]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5036]]    entropy: [array([[-0.4851,  1.1228]])]\n",
      "Loss grads: cce: [[-0.9384 -2.4408]]    entropy: [array([[-0.4845,  1.1099]])]\n",
      "Loss grads: cce: [[-0.9364 -2.575 ]]    entropy: [array([[-0.4857,  1.137 ]])]\n",
      "Loss grads: cce: [[-0.9335 -2.7881]]    entropy: [array([[-0.4872,  1.1772]])]\n",
      "Loss grads: cce: [[-0.9365 -2.564 ]]    entropy: [array([[-0.4856,  1.1348]])]\n",
      "Loss grads: cce: [[-0.9364 -2.5716]]    entropy: [array([[-0.4856,  1.1363]])]\n",
      "Loss grads: cce: [[-0.9375 -2.4994]]    entropy: [array([[-0.485 ,  1.1219]])]\n",
      "Loss grads: cce: [[-0.9334 -2.7927]]    entropy: [array([[-0.4872,  1.178 ]])]\n",
      "Loss grads: cce: [[-0.9355 -2.6327]]    entropy: [array([[-0.4861,  1.1482]])]\n",
      "Loss grads: cce: [[-0.9353 -2.648 ]]    entropy: [array([[-0.4862,  1.1511]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5198]]    entropy: [array([[-0.4852,  1.1261]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5141]]    entropy: [array([[-0.4852,  1.1249]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5229]]    entropy: [array([[-0.4852,  1.1267]])]\n",
      "Loss grads: cce: [[-0.9339 -2.754 ]]    entropy: [array([[-0.487,  1.171]])]\n",
      "Loss grads: cce: [[-0.9381 -2.4649]]    entropy: [array([[-0.4847,  1.1149]])]\n",
      "Loss grads: cce: [[-0.9334 -2.7939]]    entropy: [array([[-0.4873,  1.1783]])]\n",
      "Loss grads: cce: [[-0.9391 -2.3991]]    entropy: [array([[-0.4842,  1.1012]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5627]]    entropy: [array([[-0.4856,  1.1346]])]\n",
      "Loss grads: cce: [[-0.9363 -2.5785]]    entropy: [array([[-0.4857,  1.1377]])]\n",
      "Loss grads: cce: [[-0.9379 -2.4747]]    entropy: [array([[-0.4848,  1.1169]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4803]]    entropy: [array([[-0.4849,  1.1181]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5522]]    entropy: [array([[-0.4855,  1.1325]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5251]]    entropy: [array([[-0.4853,  1.1271]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5672]]    entropy: [array([[-0.4856,  1.1355]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4794]]    entropy: [array([[-0.4849,  1.1179]])]\n",
      "Loss grads: cce: [[-0.9361 -2.5912]]    entropy: [array([[-0.4858,  1.1402]])]\n",
      "Loss grads: cce: [[-0.937  -2.5337]]    entropy: [array([[-0.4853,  1.1288]])]\n",
      "Loss grads: cce: [[-0.9371 -2.528 ]]    entropy: [array([[-0.4853,  1.1277]])]\n",
      "Loss grads: cce: [[-0.9379 -2.4768]]    entropy: [array([[-0.4848,  1.1174]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5484]]    entropy: [array([[-0.4854,  1.1318]])]\n",
      "Loss grads: cce: [[-0.9382 -2.4574]]    entropy: [array([[-0.4847,  1.1134]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5632]]    entropy: [array([[-0.4856,  1.1347]])]\n",
      "Loss grads: cce: [[-0.9361 -2.5898]]    entropy: [array([[-0.4858,  1.1399]])]\n",
      "Loss grads: cce: [[-0.9349 -2.6819]]    entropy: [array([[-0.4865,  1.1576]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5664]]    entropy: [array([[-0.4856,  1.1353]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5627]]    entropy: [array([[-0.4856,  1.1346]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5041]]    entropy: [array([[-0.4851,  1.1229]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5165]]    entropy: [array([[-0.4852,  1.1254]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5233]]    entropy: [array([[-0.4852,  1.1268]])]\n",
      "Loss grads: cce: [[-0.9377 -2.4899]]    entropy: [array([[-0.485,  1.12 ]])]\n",
      "Loss grads: cce: [[-0.9368 -2.543 ]]    entropy: [array([[-0.4854,  1.1307]])]\n",
      "Loss grads: cce: [[-0.9375 -2.5009]]    entropy: [array([[-0.4851,  1.1222]])]\n",
      "Loss grads: cce: [[-0.9387 -2.428 ]]    entropy: [array([[-0.4844,  1.1073]])]\n",
      "Loss grads: cce: [[-0.9348 -2.6845]]    entropy: [array([[-0.4865,  1.1581]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5265]]    entropy: [array([[-0.4853,  1.1274]])]\n",
      "Loss grads: cce: [[-0.9382 -2.4577]]    entropy: [array([[-0.4847,  1.1134]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5542]]    entropy: [array([[-0.4855,  1.1329]])]\n",
      "Loss grads: cce: [[-0.9364 -2.5735]]    entropy: [array([[-0.4856,  1.1367]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5238]]    entropy: [array([[-0.4852,  1.1269]])]\n",
      "Loss grads: cce: [[-0.9341 -2.7386]]    entropy: [array([[-0.4869,  1.1682]])]\n",
      "Loss grads: cce: [[-0.9376 -2.4936]]    entropy: [array([[-0.485 ,  1.1208]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4835]]    entropy: [array([[-0.4849,  1.1187]])]\n",
      "Loss grads: cce: [[-0.936  -2.5969]]    entropy: [array([[-0.4858,  1.1413]])]\n",
      "Loss grads: cce: [[-0.9351 -2.6664]]    entropy: [array([[-0.4864,  1.1547]])]\n",
      "Loss grads: cce: [[-0.934  -2.7486]]    entropy: [array([[-0.4869,  1.17  ]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5569]]    entropy: [array([[-0.4855,  1.1334]])]\n",
      "Loss grads: cce: [[-0.9377 -2.4851]]    entropy: [array([[-0.4849,  1.119 ]])]\n",
      "Loss grads: cce: [[-0.9349 -2.678 ]]    entropy: [array([[-0.4864,  1.1568]])]\n",
      "Loss grads: cce: [[-0.9359 -2.6083]]    entropy: [array([[-0.4859,  1.1435]])]\n",
      "Loss grads: cce: [[-0.9367 -2.551 ]]    entropy: [array([[-0.4855,  1.1323]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5261]]    entropy: [array([[-0.4853,  1.1273]])]\n",
      "Loss grads: cce: [[-0.937  -2.5318]]    entropy: [array([[-0.4853,  1.1285]])]\n",
      "Loss grads: cce: [[-0.937  -2.5299]]    entropy: [array([[-0.4853,  1.1281]])]\n",
      "Loss grads: cce: [[-0.9384 -2.4424]]    entropy: [array([[-0.4845,  1.1103]])]\n",
      "Loss grads: cce: [[-0.9356 -2.6316]]    entropy: [array([[-0.4861,  1.148 ]])]\n",
      "Loss grads: cce: [[-0.9348 -2.6877]]    entropy: [array([[-0.4865,  1.1587]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5079]]    entropy: [array([[-0.4851,  1.1236]])]\n",
      "Loss grads: cce: [[-0.9381 -2.4641]]    entropy: [array([[-0.4847,  1.1147]])]\n",
      "Loss grads: cce: [[-0.937 -2.534]]    entropy: [array([[-0.4853,  1.1289]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5417]]    entropy: [array([[-0.4854,  1.1304]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5363]]    entropy: [array([[-0.4853,  1.1293]])]\n",
      "Loss grads: cce: [[-0.9377 -2.4878]]    entropy: [array([[-0.4849,  1.1196]])]\n",
      "Loss grads: cce: [[-0.9376 -2.4936]]    entropy: [array([[-0.485 ,  1.1208]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5469]]    entropy: [array([[-0.4854,  1.1315]])]\n",
      "Loss grads: cce: [[-0.935  -2.6727]]    entropy: [array([[-0.4864,  1.1558]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5388]]    entropy: [array([[-0.4854,  1.1298]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5529]]    entropy: [array([[-0.4855,  1.1327]])]\n",
      "Loss grads: cce: [[-0.936 -2.597]]    entropy: [array([[-0.4858,  1.1413]])]\n",
      "Loss grads: cce: [[-0.9353 -2.65  ]]    entropy: [array([[-0.4862,  1.1515]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5275]]    entropy: [array([[-0.4853,  1.1276]])]\n",
      "Loss grads: cce: [[-0.9377 -2.49  ]]    entropy: [array([[-0.485,  1.12 ]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5038]]    entropy: [array([[-0.4851,  1.1228]])]\n",
      "Loss grads: cce: [[-0.9377 -2.4846]]    entropy: [array([[-0.4849,  1.1189]])]\n",
      "Loss grads: cce: [[-0.9376 -2.4942]]    entropy: [array([[-0.485 ,  1.1209]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5191]]    entropy: [array([[-0.4852,  1.1259]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5691]]    entropy: [array([[-0.4856,  1.1358]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5489]]    entropy: [array([[-0.4854,  1.1319]])]\n",
      "Loss grads: cce: [[-0.9335 -2.7903]]    entropy: [array([[-0.4872,  1.1776]])]\n",
      "Loss grads: cce: [[-0.9385 -2.4364]]    entropy: [array([[-0.4845,  1.109 ]])]\n",
      "Loss grads: cce: [[-0.9354 -2.6416]]    entropy: [array([[-0.4862,  1.1499]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5578]]    entropy: [array([[-0.4855,  1.1336]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5191]]    entropy: [array([[-0.4852,  1.1259]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5099]]    entropy: [array([[-0.4851,  1.1241]])]\n",
      "Loss grads: cce: [[-0.9346 -2.7031]]    entropy: [array([[-0.4866,  1.1616]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5217]]    entropy: [array([[-0.4852,  1.1264]])]\n",
      "Loss grads: cce: [[-0.9365 -2.563 ]]    entropy: [array([[-0.4856,  1.1347]])]\n",
      "Loss grads: cce: [[-0.9339 -2.7539]]    entropy: [array([[-0.487,  1.171]])]\n",
      "Loss grads: cce: [[-0.9359 -2.6086]]    entropy: [array([[-0.4859,  1.1436]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5649]]    entropy: [array([[-0.4856,  1.135 ]])]\n",
      "Loss grads: cce: [[-0.937  -2.5329]]    entropy: [array([[-0.4853,  1.1287]])]\n",
      "Loss grads: cce: [[-0.9331 -2.8171]]    entropy: [array([[-0.4874,  1.1824]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4821]]    entropy: [array([[-0.4849,  1.1184]])]\n",
      "Loss grads: cce: [[-0.9375 -2.4994]]    entropy: [array([[-0.485 ,  1.1219]])]\n",
      "Loss grads: cce: [[-0.9375 -2.5008]]    entropy: [array([[-0.4851,  1.1222]])]\n",
      "Loss grads: cce: [[-0.9365 -2.565 ]]    entropy: [array([[-0.4856,  1.135 ]])]\n",
      "Loss grads: cce: [[-0.9368 -2.548 ]]    entropy: [array([[-0.4854,  1.1317]])]\n",
      "Loss grads: cce: [[-0.9363 -2.5771]]    entropy: [array([[-0.4857,  1.1374]])]\n",
      "Loss grads: cce: [[-0.9352 -2.6587]]    entropy: [array([[-0.4863,  1.1532]])]\n",
      "Loss grads: cce: [[-0.9376 -2.4963]]    entropy: [array([[-0.485 ,  1.1213]])]\n",
      "Loss grads: cce: [[-0.9377 -2.4844]]    entropy: [array([[-0.4849,  1.1189]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5073]]    entropy: [array([[-0.4851,  1.1235]])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss grads: cce: [[-0.9377 -2.4874]]    entropy: [array([[-0.4849,  1.1195]])]\n",
      "Loss grads: cce: [[-0.9363 -2.5786]]    entropy: [array([[-0.4857,  1.1377]])]\n",
      "Loss grads: cce: [[-0.9341 -2.7413]]    entropy: [array([[-0.4869,  1.1687]])]\n",
      "Loss grads: cce: [[-0.9375 -2.5021]]    entropy: [array([[-0.4851,  1.1225]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5166]]    entropy: [array([[-0.4852,  1.1254]])]\n",
      "Loss grads: cce: [[-0.9362 -2.5848]]    entropy: [array([[-0.4857,  1.1389]])]\n",
      "Loss grads: cce: [[-0.9352 -2.6574]]    entropy: [array([[-0.4863,  1.1529]])]\n",
      "Loss grads: cce: [[-0.9352 -2.6588]]    entropy: [array([[-0.4863,  1.1532]])]\n",
      "Loss grads: cce: [[-0.9357 -2.6181]]    entropy: [array([[-0.486 ,  1.1454]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5543]]    entropy: [array([[-0.4855,  1.1329]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5262]]    entropy: [array([[-0.4853,  1.1273]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5199]]    entropy: [array([[-0.4852,  1.1261]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5155]]    entropy: [array([[-0.4852,  1.1252]])]\n",
      "Loss grads: cce: [[-0.9347 -2.6958]]    entropy: [array([[-0.4866,  1.1602]])]\n",
      "Loss grads: cce: [[-0.9353 -2.6481]]    entropy: [array([[-0.4862,  1.1512]])]\n",
      "Loss grads: cce: [[-0.9362 -2.5881]]    entropy: [array([[-0.4858,  1.1396]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5042]]    entropy: [array([[-0.4851,  1.1229]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5143]]    entropy: [array([[-0.4852,  1.1249]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5659]]    entropy: [array([[-0.4856,  1.1352]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5361]]    entropy: [array([[-0.4853,  1.1293]])]\n",
      "Loss grads: cce: [[-0.9364 -2.5747]]    entropy: [array([[-0.4857,  1.137 ]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5649]]    entropy: [array([[-0.4856,  1.135 ]])]\n",
      "Loss grads: cce: [[-0.9325 -2.8653]]    entropy: [array([[-0.4877,  1.191 ]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5536]]    entropy: [array([[-0.4855,  1.1328]])]\n",
      "Loss grads: cce: [[-0.9384 -2.4457]]    entropy: [array([[-0.4846,  1.111 ]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5097]]    entropy: [array([[-0.4851,  1.124 ]])]\n",
      "Loss grads: cce: [[-0.9361 -2.5914]]    entropy: [array([[-0.4858,  1.1402]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5567]]    entropy: [array([[-0.4855,  1.1334]])]\n",
      "Loss grads: cce: [[-0.9363 -2.5776]]    entropy: [array([[-0.4857,  1.1375]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5263]]    entropy: [array([[-0.4853,  1.1273]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5449]]    entropy: [array([[-0.4854,  1.1311]])]\n",
      "Loss grads: cce: [[-0.9324 -2.8802]]    entropy: [array([[-0.4878,  1.1937]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5072]]    entropy: [array([[-0.4851,  1.1235]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5078]]    entropy: [array([[-0.4851,  1.1236]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5084]]    entropy: [array([[-0.4851,  1.1238]])]\n",
      "Loss grads: cce: [[-0.9351 -2.6628]]    entropy: [array([[-0.4863,  1.154 ]])]\n",
      "Loss grads: cce: [[-0.9343 -2.7229]]    entropy: [array([[-0.4868,  1.1653]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5193]]    entropy: [array([[-0.4852,  1.1259]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5548]]    entropy: [array([[-0.4855,  1.133 ]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5059]]    entropy: [array([[-0.4851,  1.1233]])]\n",
      "Loss grads: cce: [[-0.9352 -2.6591]]    entropy: [array([[-0.4863,  1.1533]])]\n",
      "Loss grads: cce: [[-0.937  -2.5355]]    entropy: [array([[-0.4853,  1.1292]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5069]]    entropy: [array([[-0.4851,  1.1235]])]\n",
      "Loss grads: cce: [[-0.9378 -2.481 ]]    entropy: [array([[-0.4849,  1.1182]])]\n",
      "Loss grads: cce: [[-0.9346 -2.7019]]    entropy: [array([[-0.4866,  1.1613]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5391]]    entropy: [array([[-0.4854,  1.1299]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4787]]    entropy: [array([[-0.4849,  1.1177]])]\n",
      "Loss grads: cce: [[-0.937  -2.5355]]    entropy: [array([[-0.4853,  1.1292]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5494]]    entropy: [array([[-0.4855,  1.132 ]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5131]]    entropy: [array([[-0.4852,  1.1247]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5251]]    entropy: [array([[-0.4853,  1.1271]])]\n",
      "Loss grads: cce: [[-0.9364 -2.5692]]    entropy: [array([[-0.4856,  1.1359]])]\n",
      "Loss grads: cce: [[-0.9362 -2.5835]]    entropy: [array([[-0.4857,  1.1387]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5407]]    entropy: [array([[-0.4854,  1.1302]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5595]]    entropy: [array([[-0.4855,  1.134 ]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5647]]    entropy: [array([[-0.4856,  1.135 ]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4794]]    entropy: [array([[-0.4849,  1.1179]])]\n",
      "Loss grads: cce: [[-0.937  -2.5351]]    entropy: [array([[-0.4853,  1.1291]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5494]]    entropy: [array([[-0.4855,  1.132 ]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5405]]    entropy: [array([[-0.4854,  1.1302]])]\n",
      "Loss grads: cce: [[-0.9318 -2.9319]]    entropy: [array([[-0.4881,  1.2026]])]\n",
      "Loss grads: cce: [[-0.9383 -2.452 ]]    entropy: [array([[-0.4846,  1.1123]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5259]]    entropy: [array([[-0.4853,  1.1273]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5441]]    entropy: [array([[-0.4854,  1.1309]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5665]]    entropy: [array([[-0.4856,  1.1353]])]\n",
      "Loss grads: cce: [[-0.935  -2.6739]]    entropy: [array([[-0.4864,  1.1561]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5449]]    entropy: [array([[-0.4854,  1.1311]])]\n",
      "Loss grads: cce: [[-0.9377 -2.4866]]    entropy: [array([[-0.4849,  1.1193]])]\n",
      "Loss grads: cce: [[-0.938  -2.4685]]    entropy: [array([[-0.4848,  1.1157]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5543]]    entropy: [array([[-0.4855,  1.1329]])]\n",
      "Loss grads: cce: [[-0.937  -2.5342]]    entropy: [array([[-0.4853,  1.1289]])]\n",
      "Loss grads: cce: [[-0.9363 -2.577 ]]    entropy: [array([[-0.4857,  1.1374]])]\n",
      "Loss grads: cce: [[-0.9357 -2.6217]]    entropy: [array([[-0.486 ,  1.1461]])]\n",
      "Loss grads: cce: [[-0.9377 -2.4871]]    entropy: [array([[-0.4849,  1.1195]])]\n",
      "Loss grads: cce: [[-0.9377 -2.4865]]    entropy: [array([[-0.4849,  1.1193]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5191]]    entropy: [array([[-0.4852,  1.1259]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5572]]    entropy: [array([[-0.4855,  1.1335]])]\n",
      "Loss grads: cce: [[-0.9375 -2.4995]]    entropy: [array([[-0.485,  1.122]])]\n",
      "Loss grads: cce: [[-0.936  -2.5991]]    entropy: [array([[-0.4858,  1.1417]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5134]]    entropy: [array([[-0.4852,  1.1248]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5383]]    entropy: [array([[-0.4854,  1.1298]])]\n",
      "Loss grads: cce: [[-0.9345 -2.7111]]    entropy: [array([[-0.4867,  1.1631]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5229]]    entropy: [array([[-0.4852,  1.1267]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5426]]    entropy: [array([[-0.4854,  1.1306]])]\n",
      "Loss grads: cce: [[-0.937  -2.5337]]    entropy: [array([[-0.4853,  1.1288]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5622]]    entropy: [array([[-0.4856,  1.1345]])]\n",
      "Loss grads: cce: [[-0.9368 -2.545 ]]    entropy: [array([[-0.4854,  1.1311]])]\n",
      "Loss grads: cce: [[-0.937  -2.5328]]    entropy: [array([[-0.4853,  1.1286]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5568]]    entropy: [array([[-0.4855,  1.1334]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5513]]    entropy: [array([[-0.4855,  1.1323]])]\n",
      "Loss grads: cce: [[-0.9377 -2.4874]]    entropy: [array([[-0.4849,  1.1195]])]\n",
      "Loss grads: cce: [[-0.9372 -2.519 ]]    entropy: [array([[-0.4852,  1.1259]])]\n",
      "Loss grads: cce: [[-0.937  -2.5349]]    entropy: [array([[-0.4853,  1.1291]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5204]]    entropy: [array([[-0.4852,  1.1262]])]\n",
      "Loss grads: cce: [[-0.9339 -2.7578]]    entropy: [array([[-0.487 ,  1.1717]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4781]]    entropy: [array([[-0.4849,  1.1176]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5289]]    entropy: [array([[-0.4853,  1.1279]])]\n",
      "Loss grads: cce: [[-0.9338 -2.7643]]    entropy: [array([[-0.4871,  1.1729]])]\n",
      "Loss grads: cce: [[-0.938  -2.4684]]    entropy: [array([[-0.4848,  1.1156]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4827]]    entropy: [array([[-0.4849,  1.1185]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5663]]    entropy: [array([[-0.4856,  1.1353]])]\n",
      "Loss grads: cce: [[-0.9348 -2.6847]]    entropy: [array([[-0.4865,  1.1581]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5514]]    entropy: [array([[-0.4855,  1.1324]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5661]]    entropy: [array([[-0.4856,  1.1353]])]\n",
      "Loss grads: cce: [[-0.9347 -2.6929]]    entropy: [array([[-0.4866,  1.1596]])]\n",
      "Loss grads: cce: [[-0.9373 -2.516 ]]    entropy: [array([[-0.4852,  1.1253]])]\n",
      "Loss grads: cce: [[-0.9356 -2.6263]]    entropy: [array([[-0.4861,  1.147 ]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5445]]    entropy: [array([[-0.4854,  1.131 ]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5581]]    entropy: [array([[-0.4855,  1.1337]])]\n",
      "Loss grads: cce: [[-0.936 -2.601]]    entropy: [array([[-0.4859,  1.1421]])]\n",
      "Loss grads: cce: [[-0.9375 -2.4981]]    entropy: [array([[-0.485 ,  1.1217]])]\n",
      "Loss grads: cce: [[-0.9379 -2.4767]]    entropy: [array([[-0.4848,  1.1173]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5186]]    entropy: [array([[-0.4852,  1.1258]])]\n",
      "Loss grads: cce: [[-0.9364 -2.5738]]    entropy: [array([[-0.4856,  1.1368]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5099]]    entropy: [array([[-0.4851,  1.1241]])]\n",
      "Loss grads: cce: [[-0.9358 -2.6148]]    entropy: [array([[-0.486 ,  1.1448]])]\n",
      "Loss grads: cce: [[-0.9379 -2.4748]]    entropy: [array([[-0.4848,  1.1169]])]\n",
      "Loss grads: cce: [[-0.938  -2.4658]]    entropy: [array([[-0.4848,  1.1151]])]\n",
      "Loss grads: cce: [[-0.9377 -2.488 ]]    entropy: [array([[-0.4849,  1.1196]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5577]]    entropy: [array([[-0.4855,  1.1336]])]\n",
      "Loss grads: cce: [[-0.9349 -2.6817]]    entropy: [array([[-0.4865,  1.1575]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5557]]    entropy: [array([[-0.4855,  1.1332]])]\n",
      "Loss grads: cce: [[-0.9361 -2.5945]]    entropy: [array([[-0.4858,  1.1408]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5541]]    entropy: [array([[-0.4855,  1.1329]])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss grads: cce: [[-0.9385 -2.4373]]    entropy: [array([[-0.4845,  1.1092]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5638]]    entropy: [array([[-0.4856,  1.1348]])]\n",
      "Loss grads: cce: [[-0.9362 -2.5892]]    entropy: [array([[-0.4858,  1.1398]])]\n",
      "Loss grads: cce: [[-0.9362 -2.583 ]]    entropy: [array([[-0.4857,  1.1386]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5099]]    entropy: [array([[-0.4851,  1.1241]])]\n",
      "Loss grads: cce: [[-0.9382 -2.457 ]]    entropy: [array([[-0.4847,  1.1133]])]\n",
      "Loss grads: cce: [[-0.9367 -2.552 ]]    entropy: [array([[-0.4855,  1.1325]])]\n",
      "Loss grads: cce: [[-0.9352 -2.6543]]    entropy: [array([[-0.4863,  1.1523]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5053]]    entropy: [array([[-0.4851,  1.1231]])]\n",
      "Loss grads: cce: [[-0.9364 -2.5731]]    entropy: [array([[-0.4856,  1.1366]])]\n",
      "Loss grads: cce: [[-0.9365 -2.563 ]]    entropy: [array([[-0.4856,  1.1346]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5492]]    entropy: [array([[-0.4855,  1.1319]])]\n",
      "Loss grads: cce: [[-0.9354 -2.6449]]    entropy: [array([[-0.4862,  1.1505]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5471]]    entropy: [array([[-0.4854,  1.1315]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5111]]    entropy: [array([[-0.4851,  1.1243]])]\n",
      "Loss grads: cce: [[-0.9376 -2.4905]]    entropy: [array([[-0.485 ,  1.1201]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5044]]    entropy: [array([[-0.4851,  1.1229]])]\n",
      "Loss grads: cce: [[-0.9357 -2.6235]]    entropy: [array([[-0.486 ,  1.1464]])]\n",
      "Loss grads: cce: [[-0.9391 -2.4045]]    entropy: [array([[-0.4842,  1.1024]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5462]]    entropy: [array([[-0.4854,  1.1313]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5123]]    entropy: [array([[-0.4851,  1.1245]])]\n",
      "Loss grads: cce: [[-0.9363 -2.5765]]    entropy: [array([[-0.4857,  1.1373]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5279]]    entropy: [array([[-0.4853,  1.1277]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5556]]    entropy: [array([[-0.4855,  1.1332]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5416]]    entropy: [array([[-0.4854,  1.1304]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5639]]    entropy: [array([[-0.4856,  1.1348]])]\n",
      "Loss grads: cce: [[-0.9363 -2.5765]]    entropy: [array([[-0.4857,  1.1373]])]\n",
      "Loss grads: cce: [[-0.9356 -2.6248]]    entropy: [array([[-0.486 ,  1.1467]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5116]]    entropy: [array([[-0.4851,  1.1244]])]\n",
      "Loss grads: cce: [[-0.933  -2.8248]]    entropy: [array([[-0.4875,  1.1838]])]\n",
      "Loss grads: cce: [[-0.937  -2.5349]]    entropy: [array([[-0.4853,  1.1291]])]\n",
      "Loss grads: cce: [[-0.9376 -2.4945]]    entropy: [array([[-0.485 ,  1.1209]])]\n",
      "Loss grads: cce: [[-0.9376 -2.4927]]    entropy: [array([[-0.485 ,  1.1206]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5213]]    entropy: [array([[-0.4852,  1.1264]])]\n",
      "Loss grads: cce: [[-0.9362 -2.5837]]    entropy: [array([[-0.4857,  1.1387]])]\n",
      "Loss grads: cce: [[-0.9361 -2.5922]]    entropy: [array([[-0.4858,  1.1404]])]\n",
      "Loss grads: cce: [[-0.9364 -2.5742]]    entropy: [array([[-0.4857,  1.1369]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5226]]    entropy: [array([[-0.4852,  1.1266]])]\n",
      "Loss grads: cce: [[-0.9376 -2.4929]]    entropy: [array([[-0.485 ,  1.1206]])]\n",
      "Loss grads: cce: [[-0.9359 -2.6046]]    entropy: [array([[-0.4859,  1.1428]])]\n",
      "Loss grads: cce: [[-0.9374 -2.507 ]]    entropy: [array([[-0.4851,  1.1235]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5266]]    entropy: [array([[-0.4853,  1.1274]])]\n",
      "Loss grads: cce: [[-0.9351 -2.6638]]    entropy: [array([[-0.4863,  1.1542]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5033]]    entropy: [array([[-0.4851,  1.1227]])]\n",
      "Loss grads: cce: [[-0.9348 -2.6877]]    entropy: [array([[-0.4865,  1.1587]])]\n",
      "Loss grads: cce: [[-0.9363 -2.5799]]    entropy: [array([[-0.4857,  1.138 ]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5063]]    entropy: [array([[-0.4851,  1.1233]])]\n",
      "Loss grads: cce: [[-0.9361 -2.5914]]    entropy: [array([[-0.4858,  1.1402]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5215]]    entropy: [array([[-0.4852,  1.1264]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5394]]    entropy: [array([[-0.4854,  1.13  ]])]\n",
      "Loss grads: cce: [[-0.937  -2.5346]]    entropy: [array([[-0.4853,  1.129 ]])]\n",
      "Loss grads: cce: [[-0.9359 -2.6049]]    entropy: [array([[-0.4859,  1.1428]])]\n",
      "Loss grads: cce: [[-0.9362 -2.5891]]    entropy: [array([[-0.4858,  1.1398]])]\n",
      "Loss grads: cce: [[-0.9379 -2.474 ]]    entropy: [array([[-0.4848,  1.1168]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5253]]    entropy: [array([[-0.4853,  1.1271]])]\n",
      "Loss grads: cce: [[-0.9373 -2.515 ]]    entropy: [array([[-0.4852,  1.1251]])]\n",
      "Loss grads: cce: [[-0.9369 -2.541 ]]    entropy: [array([[-0.4854,  1.1303]])]\n",
      "Loss grads: cce: [[-0.9357 -2.6216]]    entropy: [array([[-0.486 ,  1.1461]])]\n",
      "Loss grads: cce: [[-0.9364 -2.5732]]    entropy: [array([[-0.4856,  1.1366]])]\n",
      "Loss grads: cce: [[-0.935  -2.6744]]    entropy: [array([[-0.4864,  1.1562]])]\n",
      "Loss grads: cce: [[-0.9362 -2.5879]]    entropy: [array([[-0.4858,  1.1395]])]\n",
      "Loss grads: cce: [[-0.9361 -2.5928]]    entropy: [array([[-0.4858,  1.1405]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5649]]    entropy: [array([[-0.4856,  1.135 ]])]\n",
      "Loss grads: cce: [[-0.9363 -2.5789]]    entropy: [array([[-0.4857,  1.1378]])]\n",
      "Loss grads: cce: [[-0.9375 -2.5004]]    entropy: [array([[-0.485 ,  1.1221]])]\n",
      "Loss grads: cce: [[-0.9362 -2.5856]]    entropy: [array([[-0.4857,  1.1391]])]\n",
      "Loss grads: cce: [[-0.9347 -2.6968]]    entropy: [array([[-0.4866,  1.1604]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5179]]    entropy: [array([[-0.4852,  1.1257]])]\n",
      "Loss grads: cce: [[-0.9363 -2.5807]]    entropy: [array([[-0.4857,  1.1381]])]\n",
      "Loss grads: cce: [[-0.9379 -2.4778]]    entropy: [array([[-0.4849,  1.1175]])]\n",
      "Loss grads: cce: [[-0.9351 -2.6646]]    entropy: [array([[-0.4863,  1.1543]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4835]]    entropy: [array([[-0.4849,  1.1187]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5491]]    entropy: [array([[-0.4855,  1.1319]])]\n",
      "Loss grads: cce: [[-0.9375 -2.5012]]    entropy: [array([[-0.4851,  1.1223]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5143]]    entropy: [array([[-0.4852,  1.125 ]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4816]]    entropy: [array([[-0.4849,  1.1183]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5222]]    entropy: [array([[-0.4852,  1.1265]])]\n",
      "Loss grads: cce: [[-0.9358 -2.6106]]    entropy: [array([[-0.4859,  1.144 ]])]\n",
      "Loss grads: cce: [[-0.9371 -2.529 ]]    entropy: [array([[-0.4853,  1.1279]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5168]]    entropy: [array([[-0.4852,  1.1254]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5568]]    entropy: [array([[-0.4855,  1.1334]])]\n",
      "Loss grads: cce: [[-0.9363 -2.5807]]    entropy: [array([[-0.4857,  1.1381]])]\n",
      "Loss grads: cce: [[-0.937  -2.5348]]    entropy: [array([[-0.4853,  1.1291]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5133]]    entropy: [array([[-0.4852,  1.1247]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5412]]    entropy: [array([[-0.4854,  1.1303]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5286]]    entropy: [array([[-0.4853,  1.1278]])]\n",
      "Loss grads: cce: [[-0.9353 -2.6496]]    entropy: [array([[-0.4862,  1.1514]])]\n",
      "Loss grads: cce: [[-0.9375 -2.5005]]    entropy: [array([[-0.485 ,  1.1222]])]\n",
      "Loss grads: cce: [[-0.9375 -2.498 ]]    entropy: [array([[-0.485 ,  1.1216]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5533]]    entropy: [array([[-0.4855,  1.1327]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5633]]    entropy: [array([[-0.4856,  1.1347]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5449]]    entropy: [array([[-0.4854,  1.1311]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5091]]    entropy: [array([[-0.4851,  1.1239]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5521]]    entropy: [array([[-0.4855,  1.1325]])]\n",
      "Loss grads: cce: [[-0.938  -2.4662]]    entropy: [array([[-0.4848,  1.1152]])]\n",
      "Loss grads: cce: [[-0.9377 -2.4846]]    entropy: [array([[-0.4849,  1.1189]])]\n",
      "Loss grads: cce: [[-0.9344 -2.7144]]    entropy: [array([[-0.4867,  1.1637]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4832]]    entropy: [array([[-0.4849,  1.1187]])]\n",
      "Loss grads: cce: [[-0.9357 -2.6181]]    entropy: [array([[-0.486 ,  1.1454]])]\n",
      "Loss grads: cce: [[-0.937  -2.5337]]    entropy: [array([[-0.4853,  1.1288]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5246]]    entropy: [array([[-0.4853,  1.127 ]])]\n",
      "Loss grads: cce: [[-0.9379 -2.4748]]    entropy: [array([[-0.4848,  1.1169]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5413]]    entropy: [array([[-0.4854,  1.1303]])]\n",
      "Loss grads: cce: [[-0.9352 -2.6578]]    entropy: [array([[-0.4863,  1.153 ]])]\n",
      "Loss grads: cce: [[-0.9375 -2.4981]]    entropy: [array([[-0.485 ,  1.1217]])]\n",
      "Loss grads: cce: [[-0.9364 -2.5708]]    entropy: [array([[-0.4856,  1.1362]])]\n",
      "Loss grads: cce: [[-0.9377 -2.4851]]    entropy: [array([[-0.4849,  1.119 ]])]\n",
      "Loss grads: cce: [[-0.9359 -2.6057]]    entropy: [array([[-0.4859,  1.143 ]])]\n",
      "Loss grads: cce: [[-0.9363 -2.5797]]    entropy: [array([[-0.4857,  1.1379]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5266]]    entropy: [array([[-0.4853,  1.1274]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5147]]    entropy: [array([[-0.4852,  1.125 ]])]\n",
      "Loss grads: cce: [[-0.9359 -2.6099]]    entropy: [array([[-0.4859,  1.1438]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5427]]    entropy: [array([[-0.4854,  1.1306]])]\n",
      "Loss grads: cce: [[-0.9358 -2.6116]]    entropy: [array([[-0.4859,  1.1441]])]\n",
      "Loss grads: cce: [[-0.9377 -2.4879]]    entropy: [array([[-0.4849,  1.1196]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5369]]    entropy: [array([[-0.4854,  1.1295]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5476]]    entropy: [array([[-0.4854,  1.1316]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5519]]    entropy: [array([[-0.4855,  1.1324]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5449]]    entropy: [array([[-0.4854,  1.1311]])]\n",
      "Loss grads: cce: [[-0.9366 -2.556 ]]    entropy: [array([[-0.4855,  1.1333]])]\n",
      "Loss grads: cce: [[-0.9364 -2.5696]]    entropy: [array([[-0.4856,  1.1359]])]\n",
      "Loss grads: cce: [[-0.936  -2.6027]]    entropy: [array([[-0.4859,  1.1424]])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss grads: cce: [[-0.9364 -2.5758]]    entropy: [array([[-0.4857,  1.1372]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5238]]    entropy: [array([[-0.4852,  1.1268]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5366]]    entropy: [array([[-0.4853,  1.1294]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5686]]    entropy: [array([[-0.4856,  1.1357]])]\n",
      "Loss grads: cce: [[-0.937  -2.5339]]    entropy: [array([[-0.4853,  1.1289]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5521]]    entropy: [array([[-0.4855,  1.1325]])]\n",
      "Loss grads: cce: [[-0.9375 -2.4985]]    entropy: [array([[-0.485 ,  1.1218]])]\n",
      "Loss grads: cce: [[-0.9362 -2.5884]]    entropy: [array([[-0.4858,  1.1396]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5081]]    entropy: [array([[-0.4851,  1.1237]])]\n",
      "Loss grads: cce: [[-0.9377 -2.4901]]    entropy: [array([[-0.485 ,  1.1201]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5446]]    entropy: [array([[-0.4854,  1.131 ]])]\n",
      "Loss grads: cce: [[-0.9355 -2.6367]]    entropy: [array([[-0.4861,  1.149 ]])]\n",
      "Loss grads: cce: [[-0.937  -2.5321]]    entropy: [array([[-0.4853,  1.1285]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5545]]    entropy: [array([[-0.4855,  1.133 ]])]\n",
      "Loss grads: cce: [[-0.937  -2.5315]]    entropy: [array([[-0.4853,  1.1284]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5461]]    entropy: [array([[-0.4854,  1.1313]])]\n",
      "Loss grads: cce: [[-0.9375 -2.5014]]    entropy: [array([[-0.4851,  1.1223]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5683]]    entropy: [array([[-0.4856,  1.1357]])]\n",
      "Loss grads: cce: [[-0.936  -2.5988]]    entropy: [array([[-0.4858,  1.1417]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5677]]    entropy: [array([[-0.4856,  1.1356]])]\n",
      "Loss grads: cce: [[-0.9369 -2.537 ]]    entropy: [array([[-0.4854,  1.1295]])]\n",
      "Loss grads: cce: [[-0.9361 -2.5907]]    entropy: [array([[-0.4858,  1.1401]])]\n",
      "Loss grads: cce: [[-0.9361 -2.5909]]    entropy: [array([[-0.4858,  1.1401]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5529]]    entropy: [array([[-0.4855,  1.1326]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5517]]    entropy: [array([[-0.4855,  1.1324]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5423]]    entropy: [array([[-0.4854,  1.1305]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5666]]    entropy: [array([[-0.4856,  1.1354]])]\n",
      "Loss grads: cce: [[-0.9364 -2.5744]]    entropy: [array([[-0.4857,  1.1369]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5408]]    entropy: [array([[-0.4854,  1.1303]])]\n",
      "Loss grads: cce: [[-0.9354 -2.6435]]    entropy: [array([[-0.4862,  1.1503]])]\n",
      "Loss grads: cce: [[-0.9357 -2.6222]]    entropy: [array([[-0.486 ,  1.1462]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5432]]    entropy: [array([[-0.4854,  1.1307]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5403]]    entropy: [array([[-0.4854,  1.1301]])]\n",
      "Loss grads: cce: [[-0.9375 -2.5009]]    entropy: [array([[-0.4851,  1.1222]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5478]]    entropy: [array([[-0.4854,  1.1316]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5485]]    entropy: [array([[-0.4854,  1.1318]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5269]]    entropy: [array([[-0.4853,  1.1275]])]\n",
      "Loss grads: cce: [[-0.9364 -2.5708]]    entropy: [array([[-0.4856,  1.1362]])]\n",
      "Loss grads: cce: [[-0.9346 -2.7047]]    entropy: [array([[-0.4866,  1.1619]])]\n",
      "Loss grads: cce: [[-0.9375 -2.4995]]    entropy: [array([[-0.485,  1.122]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5185]]    entropy: [array([[-0.4852,  1.1258]])]\n",
      "Loss grads: cce: [[-0.9332 -2.8091]]    entropy: [array([[-0.4874,  1.181 ]])]\n",
      "Loss grads: cce: [[-0.9378 -2.4809]]    entropy: [array([[-0.4849,  1.1182]])]\n",
      "Loss grads: cce: [[-0.9366 -2.559 ]]    entropy: [array([[-0.4855,  1.1339]])]\n",
      "Loss grads: cce: [[-0.937  -2.5303]]    entropy: [array([[-0.4853,  1.1282]])]\n",
      "Loss grads: cce: [[-0.9362 -2.5889]]    entropy: [array([[-0.4858,  1.1397]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5122]]    entropy: [array([[-0.4851,  1.1245]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5272]]    entropy: [array([[-0.4853,  1.1275]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5476]]    entropy: [array([[-0.4854,  1.1316]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5455]]    entropy: [array([[-0.4854,  1.1312]])]\n",
      "Loss grads: cce: [[-0.9347 -2.696 ]]    entropy: [array([[-0.4866,  1.1602]])]\n",
      "Loss grads: cce: [[-0.937  -2.5352]]    entropy: [array([[-0.4853,  1.1291]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5651]]    entropy: [array([[-0.4856,  1.1351]])]\n",
      "Loss grads: cce: [[-0.937 -2.535]]    entropy: [array([[-0.4853,  1.1291]])]\n",
      "Loss grads: cce: [[-0.9359 -2.6068]]    entropy: [array([[-0.4859,  1.1432]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5402]]    entropy: [array([[-0.4854,  1.1301]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5106]]    entropy: [array([[-0.4851,  1.1242]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5033]]    entropy: [array([[-0.4851,  1.1227]])]\n",
      "Loss grads: cce: [[-0.9362 -2.5828]]    entropy: [array([[-0.4857,  1.1385]])]\n",
      "Loss grads: cce: [[-0.9372 -2.5203]]    entropy: [array([[-0.4852,  1.1261]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5387]]    entropy: [array([[-0.4854,  1.1298]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5505]]    entropy: [array([[-0.4855,  1.1322]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5522]]    entropy: [array([[-0.4855,  1.1325]])]\n",
      "Loss grads: cce: [[-0.9336 -2.776 ]]    entropy: [array([[-0.4871,  1.175 ]])]\n",
      "Loss grads: cce: [[-0.9373 -2.51  ]]    entropy: [array([[-0.4851,  1.1241]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5666]]    entropy: [array([[-0.4856,  1.1354]])]\n",
      "Loss grads: cce: [[-0.9349 -2.6792]]    entropy: [array([[-0.4865,  1.1571]])]\n",
      "Loss grads: cce: [[-0.9359 -2.6092]]    entropy: [array([[-0.4859,  1.1437]])]\n",
      "Loss grads: cce: [[-0.9381 -2.461 ]]    entropy: [array([[-0.4847,  1.1141]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5076]]    entropy: [array([[-0.4851,  1.1236]])]\n",
      "Loss grads: cce: [[-0.9369 -2.54  ]]    entropy: [array([[-0.4854,  1.1301]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5253]]    entropy: [array([[-0.4853,  1.1272]])]\n",
      "Loss grads: cce: [[-0.9358 -2.6127]]    entropy: [array([[-0.486 ,  1.1444]])]\n",
      "Loss grads: cce: [[-0.9364 -2.5716]]    entropy: [array([[-0.4856,  1.1363]])]\n",
      "Loss grads: cce: [[-0.9328 -2.843 ]]    entropy: [array([[-0.4876,  1.1871]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5639]]    entropy: [array([[-0.4856,  1.1348]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5153]]    entropy: [array([[-0.4852,  1.1251]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5277]]    entropy: [array([[-0.4853,  1.1276]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5513]]    entropy: [array([[-0.4855,  1.1323]])]\n",
      "Loss grads: cce: [[-0.937  -2.5329]]    entropy: [array([[-0.4853,  1.1287]])]\n",
      "Loss grads: cce: [[-0.9376 -2.4942]]    entropy: [array([[-0.485 ,  1.1209]])]\n",
      "Loss grads: cce: [[-0.9365 -2.5679]]    entropy: [array([[-0.4856,  1.1356]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5279]]    entropy: [array([[-0.4853,  1.1277]])]\n",
      "Loss grads: cce: [[-0.937  -2.5301]]    entropy: [array([[-0.4853,  1.1281]])]\n",
      "Loss grads: cce: [[-0.937  -2.5294]]    entropy: [array([[-0.4853,  1.128 ]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5582]]    entropy: [array([[-0.4855,  1.1337]])]\n",
      "Loss grads: cce: [[-0.9373 -2.511 ]]    entropy: [array([[-0.4851,  1.1243]])]\n",
      "Loss grads: cce: [[-0.9363 -2.5769]]    entropy: [array([[-0.4857,  1.1374]])]\n",
      "Loss grads: cce: [[-0.9374 -2.5086]]    entropy: [array([[-0.4851,  1.1238]])]\n",
      "Loss grads: cce: [[-0.937  -2.5311]]    entropy: [array([[-0.4853,  1.1283]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5248]]    entropy: [array([[-0.4853,  1.1271]])]\n",
      "Loss grads: cce: [[-0.9349 -2.681 ]]    entropy: [array([[-0.4865,  1.1574]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5383]]    entropy: [array([[-0.4854,  1.1297]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5567]]    entropy: [array([[-0.4855,  1.1334]])]\n",
      "Loss grads: cce: [[-0.9365 -2.569 ]]    entropy: [array([[-0.4856,  1.1358]])]\n",
      "Loss grads: cce: [[-0.9366 -2.562 ]]    entropy: [array([[-0.4856,  1.1344]])]\n",
      "Loss grads: cce: [[-0.9373 -2.514 ]]    entropy: [array([[-0.4852,  1.1249]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5475]]    entropy: [array([[-0.4854,  1.1316]])]\n",
      "Loss grads: cce: [[-0.9377 -2.49  ]]    entropy: [array([[-0.485,  1.12 ]])]\n",
      "Loss grads: cce: [[-0.9367 -2.5538]]    entropy: [array([[-0.4855,  1.1328]])]\n",
      "Loss grads: cce: [[-0.9364 -2.5737]]    entropy: [array([[-0.4856,  1.1368]])]\n",
      "Loss grads: cce: [[-0.937 -2.532]]    entropy: [array([[-0.4853,  1.1285]])]\n",
      "Loss grads: cce: [[-0.9363 -2.5803]]    entropy: [array([[-0.4857,  1.138 ]])]\n",
      "Loss grads: cce: [[-0.9373 -2.5097]]    entropy: [array([[-0.4851,  1.124 ]])]\n",
      "Loss grads: cce: [[-0.9363 -2.5825]]    entropy: [array([[-0.4857,  1.1385]])]\n",
      "Loss grads: cce: [[-0.9364 -2.5696]]    entropy: [array([[-0.4856,  1.1359]])]\n",
      "Loss grads: cce: [[-0.9371 -2.5272]]    entropy: [array([[-0.4853,  1.1275]])]\n",
      "Loss grads: cce: [[-0.9366 -2.5557]]    entropy: [array([[-0.4855,  1.1332]])]\n",
      "Loss grads: cce: [[-0.9363 -2.5787]]    entropy: [array([[-0.4857,  1.1377]])]\n",
      "Loss grads: cce: [[-0.9375 -2.4998]]    entropy: [array([[-0.485,  1.122]])]\n",
      "Loss grads: cce: [[-0.9362 -2.5868]]    entropy: [array([[-0.4858,  1.1393]])]\n",
      "Loss grads: cce: [[-0.9368 -2.5471]]    entropy: [array([[-0.4854,  1.1315]])]\n",
      "Loss grads: cce: [[-0.9369 -2.5378]]    entropy: [array([[-0.4854,  1.1296]])]\n",
      "Loss grads: cce: [[-0.9352 -2.66  ]]    entropy: [array([[-0.4863,  1.1534]])]\n",
      "Loss grads: cce: [[-0.9359 -2.6101]]    entropy: [array([[-0.4859,  1.1439]])]\n",
      "[0.961 0.039]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "for t in range(10000):\n",
    "    x = np.random.random((mb, nin))\n",
    "    losses, metrics = model.fit(x, y_, metrics=[accuracy])\n",
    "    if t % 10 == 0:\n",
    "        #print(\"accuracy:\", metrics[0], \"  entropy:\", losses[\"entropy\"], \"   cce:\", losses[\"cce\"])\n",
    "        y = model.compute(x)[0]\n",
    "        avg = np.mean(y, axis=0)\n",
    "        p = avg[:2]\n",
    "        ma = ma + 0.1*(p - ma)\n",
    "        record.append(ma)\n",
    "        \n",
    "        print(\"Loss grads: cce:\", model[\"cce\"].Grads, \"   entropy:\", model[\"entropy\"].Grads)\n",
    "\n",
    "pyplot.plot(record)\n",
    "print(ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687e8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
